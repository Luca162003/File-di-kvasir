{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee5cecc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /users/lanza/cvision\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "#os.chdir(\"/Users/lucatognari/Pitone/File-di-python/Trus\")  # Change to your desired path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd09ca06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'c-trus' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/wwu-mmll/c-trus.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f4f8568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BlurPool(nn.Module):\n",
    "    def __init__(self, channels, filt_size=3, stride=2):\n",
    "        super().__init__()\n",
    "        self.stride = stride\n",
    "        self.channels = channels\n",
    "        \n",
    "        if filt_size == 3:\n",
    "            a = torch.tensor([1., 2., 1.])\n",
    "        elif filt_size == 5:\n",
    "            a = torch.tensor([1., 4., 6., 4., 1.])\n",
    "        \n",
    "        a = a / a.sum()\n",
    "        filt = a[:, None] * a[None, :]  # 2D kernel\n",
    "        filt = filt[None, None, :, :].repeat(channels, 1, 1, 1)\n",
    "        \n",
    "        self.register_buffer('filt', filt)\n",
    "        self.pad = nn.ReflectionPad2d(filt_size // 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pad(x)\n",
    "        return F.conv2d(x, self.filt, stride=self.stride, groups=self.channels)\n",
    "\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.squeeze = nn.AdaptiveAvgPool2d(1)\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.squeeze(x).view(b, c)\n",
    "        y = self.excitation(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, g, x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        return x * psi\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_se=True):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "        self.se = SEBlock(out_channels) if use_se else nn.Identity()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.residual = nn.Conv2d(in_channels, out_channels, kernel_size=1) if in_channels != out_channels else nn.Identity()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.relu(self.se(self.conv(x)) + self.residual(x))\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, features=[64, 128, 256, 512], dropout=0.2, deep_supervision=True, use_se=True, use_blurpool=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.pools = nn.ModuleList()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.attention_blocks = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.deep_supervision = deep_supervision\n",
    "        \n",
    "        # Downsampling path\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature, use_se=use_se))\n",
    "            if use_blurpool:\n",
    "                self.pools.append(BlurPool(feature, filt_size=3, stride=2))\n",
    "            else:\n",
    "                self.pools.append(nn.Conv2d(feature, feature, kernel_size=3, \n",
    "                                           stride=2, padding=1))\n",
    "            in_channels = feature\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            DoubleConv(features[-1], features[-1]*2, use_se=use_se),\n",
    "            nn.Dropout2d(dropout) if dropout > 0 else nn.Identity()\n",
    "        )\n",
    "        \n",
    "        # Upsampling path\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(nn.Sequential(\n",
    "                nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2),\n",
    "                nn.Dropout2d(dropout) if dropout > 0 else nn.Identity()\n",
    "            ))\n",
    "            self.ups.append(DoubleConv(feature*2, feature, use_se=use_se))\n",
    "            self.attention_blocks.append(AttentionBlock(F_g=feature, F_l=feature, F_int=feature // 2))\n",
    "        \n",
    "        # Final output\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "        \n",
    "        # Deep supervision outputs\n",
    "        if deep_supervision:\n",
    "            self.deep_outputs = nn.ModuleList([\n",
    "                nn.Conv2d(feature, out_channels, kernel_size=1) \n",
    "                for feature in reversed(features)\n",
    "            ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "        \n",
    "        # Down path\n",
    "        for i, down in enumerate(self.downs):\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pools[i](x)\n",
    "        \n",
    "        # Bottleneck\n",
    "        x = self.bottleneck(x)\n",
    "        \n",
    "        # Reverse skip connections\n",
    "        skip_connections = skip_connections[::-1]\n",
    "        \n",
    "        deep_outputs = []\n",
    "        \n",
    "        # Up path with attention\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)\n",
    "            skip_connection = skip_connections[idx // 2]\n",
    "            \n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = F.interpolate(x, size=skip_connection.shape[2:], mode='bilinear', align_corners=False)\n",
    "            \n",
    "            attn = self.attention_blocks[idx // 2](x, skip_connection)\n",
    "            concat_skip = torch.cat((attn, x), dim=1)\n",
    "            x = self.ups[idx + 1](concat_skip)\n",
    "            \n",
    "            if self.deep_supervision and self.training and idx // 2 < len(self.deep_outputs):\n",
    "                deep_outputs.append(self.deep_outputs[idx // 2](x))\n",
    "        \n",
    "        final_out = self.final_conv(x)\n",
    "        \n",
    "        if self.deep_supervision and self.training:\n",
    "            return final_out, deep_outputs\n",
    "        return final_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf09c9b6",
   "metadata": {},
   "source": [
    "Refined Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d5b49c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BlurPool(nn.Module):\n",
    "    \"\"\"Anti-aliasing blur pooling layer\"\"\"\n",
    "    def __init__(self, channels, filt_size=3, stride=2):\n",
    "        super().__init__()\n",
    "        self.stride = stride\n",
    "        self.channels = channels\n",
    "        \n",
    "        if filt_size == 3:\n",
    "            a = torch.tensor([1., 2., 1.])\n",
    "        elif filt_size == 5:\n",
    "            a = torch.tensor([1., 4., 6., 4., 1.])\n",
    "        \n",
    "        a = a / a.sum()\n",
    "        filt = a[:, None] * a[None, :]  # 2D kernel\n",
    "        filt = filt[None, None, :, :].repeat(channels, 1, 1, 1)\n",
    "        \n",
    "        self.register_buffer('filt', filt)\n",
    "        self.pad = nn.ReflectionPad2d(filt_size // 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pad(x)\n",
    "        return F.conv2d(x, self.filt, stride=self.stride, groups=self.channels)\n",
    "\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    \"\"\"Squeeze-and-Excitation block for channel attention\"\"\"\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.squeeze = nn.AdaptiveAvgPool2d(1)\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Linear(channels, max(channels // reduction, 1), bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(max(channels // reduction, 1), channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.squeeze(x).view(b, c)\n",
    "        y = self.excitation(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    \"\"\"Spatial attention gate for skip connections\"\"\"\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, g, x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        return x * psi\n",
    "\n",
    "\n",
    "class RefinedSkipConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    Refine skip connections before concatenation.\n",
    "    Reduces noise and improves feature quality.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.refine = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.se = SEBlock(channels)\n",
    "    \n",
    "    def forward(self, skip):\n",
    "        skip_refined = self.refine(skip)\n",
    "        skip_refined = self.se(skip_refined)\n",
    "        return skip_refined\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Double convolution with residual connection, SE block, and stratified dropout.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, use_se=True, dropout_rate=0.0):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(dropout_rate) if dropout_rate > 0 else nn.Identity(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "        self.se = SEBlock(out_channels) if use_se else nn.Identity()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.residual = nn.Conv2d(in_channels, out_channels, kernel_size=1) \\\n",
    "                       if in_channels != out_channels else nn.Identity()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.relu(self.se(self.conv(x)) + self.residual(x))\n",
    "\n",
    "\n",
    "class DilatedDoubleConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Dilated double convolution for increased receptive field.\n",
    "    Used in bottleneck for multi-scale context.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, dilation=2):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                      padding=dilation, dilation=dilation),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
    "                      padding=dilation, dilation=dilation),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "        self.se = SEBlock(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.residual = nn.Conv2d(in_channels, out_channels, 1) \\\n",
    "                       if in_channels != out_channels else nn.Identity()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.relu(self.se(self.conv(x)) + self.residual(x))\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=1, out_channels=1, features=[64, 128, 256, 512], \n",
    "                 dropout=0.2, deep_supervision=True, use_se=True, use_blurpool=True,\n",
    "                 use_skip_refinement=True, dropout_rate=0.1):\n",
    "        super(UNet, self).__init__()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.pools = nn.ModuleList()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.attention_blocks = nn.ModuleList()\n",
    "        self.refined_skips = nn.ModuleList() if use_skip_refinement else None\n",
    "        self.deep_supervision = deep_supervision\n",
    "        self.use_skip_refinement = use_skip_refinement\n",
    "        \n",
    "        # Downsampling path\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature, use_se=use_se, \n",
    "                                         dropout_rate=dropout_rate))\n",
    "            if use_blurpool:\n",
    "                self.pools.append(BlurPool(feature, filt_size=3, stride=2))\n",
    "            else:\n",
    "                self.pools.append(nn.Conv2d(feature, feature, kernel_size=3, \n",
    "                                           stride=2, padding=1))\n",
    "            in_channels = feature\n",
    "        \n",
    "        # Bottleneck with dilated convolutions for larger receptive field\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            DilatedDoubleConv(features[-1], features[-1]*2, dilation=2),\n",
    "            nn.Dropout2d(dropout) if dropout > 0 else nn.Identity()\n",
    "        )\n",
    "        \n",
    "        # Upsampling path\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(nn.Sequential(\n",
    "                nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2),\n",
    "                nn.Dropout2d(dropout) if dropout > 0 else nn.Identity()\n",
    "            ))\n",
    "            self.ups.append(DoubleConv(feature*2, feature, use_se=use_se, \n",
    "                                       dropout_rate=dropout_rate))\n",
    "            self.attention_blocks.append(AttentionBlock(F_g=feature, F_l=feature, \n",
    "                                                        F_int=feature // 2))\n",
    "            \n",
    "            # Add skip refinement modules\n",
    "            if use_skip_refinement:\n",
    "                self.refined_skips.append(RefinedSkipConnection(feature))\n",
    "        \n",
    "        # Final output\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "        \n",
    "        # Deep supervision outputs\n",
    "        if deep_supervision:\n",
    "            self.deep_outputs = nn.ModuleList([\n",
    "                nn.Conv2d(feature, out_channels, kernel_size=1) \n",
    "                for feature in reversed(features)\n",
    "            ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "        \n",
    "        # Downsampling path\n",
    "        for i, down in enumerate(self.downs):\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pools[i](x)\n",
    "        \n",
    "        # Bottleneck\n",
    "        x = self.bottleneck(x)\n",
    "        \n",
    "        # Reverse skip connections\n",
    "        skip_connections = skip_connections[::-1]\n",
    "        \n",
    "        deep_outputs = []\n",
    "        \n",
    "        # Upsampling path with attention and skip refinement\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)\n",
    "            skip_connection = skip_connections[idx // 2]\n",
    "            \n",
    "            # Handle shape mismatch\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = F.interpolate(x, size=skip_connection.shape[2:], \n",
    "                                 mode='bilinear', align_corners=False)\n",
    "            \n",
    "            # Spatial attention gate\n",
    "            attn = self.attention_blocks[idx // 2](x, skip_connection)\n",
    "            \n",
    "            # Refine skip connection if enabled\n",
    "            if self.use_skip_refinement:\n",
    "                skip_refined = self.refined_skips[idx // 2](skip_connection)\n",
    "                skip_to_concat = attn * skip_refined\n",
    "            else:\n",
    "                skip_to_concat = attn\n",
    "            \n",
    "            # Concatenate refined skip with upsampled features\n",
    "            concat_skip = torch.cat((skip_to_concat, x), dim=1)\n",
    "            x = self.ups[idx + 1](concat_skip)\n",
    "            \n",
    "            # Deep supervision\n",
    "            if self.deep_supervision and self.training and idx // 2 < len(self.deep_outputs):\n",
    "                deep_outputs.append(self.deep_outputs[idx // 2](x))\n",
    "        \n",
    "        final_out = self.final_conv(x)\n",
    "        \n",
    "        if self.deep_supervision and self.training:\n",
    "            return final_out, deep_outputs\n",
    "        return final_out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a89d12cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "class TrusDataset(Dataset):\n",
    "    def __init__(self, image_paths, mask_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.image_paths[idx], cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.imread(self.mask_paths[idx], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        #image = image.astype(np.float32) / 255.0\n",
    "        mask = mask.astype(np.float32) / 255.0\n",
    "\n",
    "    \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "        \n",
    "        if image.dim() == 2:\n",
    "            image = image.unsqueeze(0)\n",
    "        if mask.dim() == 2:\n",
    "            mask = mask.unsqueeze(0)\n",
    "        mask = (mask > 0.5).float()\n",
    "\n",
    "        return image, mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9c0344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SmartDiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super(SmartDiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        pred = torch.sigmoid(pred)\n",
    "        pred = pred.view(pred.size(0), -1)\n",
    "        target = target.view(target.size(0), -1)\n",
    "        \n",
    "        intersection = (pred * target).sum(dim=1)\n",
    "        union = pred.sum(dim=1) + target.sum(dim=1)\n",
    "        \n",
    "        # Identify empty targets\n",
    "        target_sum = target.sum(dim=1)\n",
    "        is_empty = target_sum == 0\n",
    "        \n",
    "        # For non-empty targets: standard Dice\n",
    "        dice_non_empty = (2.0 * intersection + self.smooth) / (union + self.smooth)\n",
    "        \n",
    "        # For empty targets: penalize any prediction\n",
    "        # If pred_sum is 0 (correct), this gives 1.0 (good)\n",
    "        # If pred_sum > 0 (wrong), this approaches 0 (bad)\n",
    "        pred_sum = pred.sum(dim=1)\n",
    "        dice_empty = 1.0 / (1.0 + pred_sum)  # Goes to 1 when pred_sum=0, to 0 when pred_sum is large\n",
    "        \n",
    "        # Combine based on mask type\n",
    "        dice = torch.where(is_empty, dice_empty, dice_non_empty)\n",
    "        \n",
    "        return 1.0 - dice.mean()\n",
    "\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, smooth=1e-6):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "        self.dice = SmartDiceLoss(smooth=smooth)\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        bce_loss = self.bce(pred, target)  # BCE handles empty masks naturally\n",
    "        dice_loss = self.dice(pred, target)\n",
    "        return self.alpha * bce_loss + (1.0 - self.alpha) * dice_loss   \n",
    "\n",
    "def dice_coefficient(pred, target, threshold=0.5, smooth=1e-6, ignore_empty=False):\n",
    "    \"\"\"Evaluation metric - apply sigmoid if pred is logits\"\"\"\n",
    "    if pred.min() < 0 or pred.max() > 1:\n",
    "        pred = torch.sigmoid(pred)\n",
    "    \n",
    "    pred = (pred > threshold).float()\n",
    "    pred = pred.view(pred.size(0), -1)\n",
    "    target = target.view(target.size(0), -1)\n",
    "    \n",
    "    intersection = (pred * target).sum(dim=1)\n",
    "    union = pred.sum(dim=1) + target.sum(dim=1)\n",
    "    dice = (2.0 * intersection + smooth) / (union + smooth)\n",
    "    \n",
    "    if ignore_empty:\n",
    "        target_sum = target.sum(dim=1)\n",
    "        non_empty_mask = target_sum > 0\n",
    "        if non_empty_mask.sum() > 0:\n",
    "            dice = dice[non_empty_mask]\n",
    "        else:\n",
    "            return torch.tensor(1.0, device=pred.device)  # All empty\n",
    "    \n",
    "    return dice.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d81cb82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Original image size: 580x360\n",
      "Resizing to: 320x198 (preserving aspect ratio)\n",
      "Total files in directory: 827\n",
      "After CSV quality filter (quality != 'low'): 480\n",
      "\n",
      "================================================================================\n",
      "FILTERING SUMMARY:\n",
      "================================================================================\n",
      "Total files: 827\n",
      "After CSV filter (quality != 'low'): 480\n",
      "After mask content filter: 0\n",
      "  ↳ Removed by CSV: 347\n",
      "  ↳ Removed by mask content: 0\n",
      "Final dataset size: 0\n",
      "\n",
      "Files removed by mask content:\n",
      "\n",
      "================================================================================\n",
      "DATA SPLIT:\n",
      "================================================================================\n",
      "Train: 336 (70.0%)\n",
      "Val:   72 (15.0%)\n",
      "Test:  72 (15.0%)\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "\n",
    "IMAGE_DIR = \"c-trus/original\"\n",
    "MASK_DIR = \"c-trus/labels\"\n",
    "IMAGE_SIZE = 320\n",
    "RESIZE_HEIGHT = int(IMAGE_SIZE * 360 / 580)\n",
    "BATCH_SIZE = 4\n",
    "DEVICE = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Original image size: 580x360\")\n",
    "print(f\"Resizing to: {IMAGE_SIZE}x{RESIZE_HEIGHT} (preserving aspect ratio)\")\n",
    "\n",
    "quality_df = pd.read_csv('c-trus/c-trus.csv')\n",
    "good_files = set(quality_df[quality_df[\"quality_name\"] != \"low\"][\"file\"])\n",
    "\n",
    "csv_image_paths = sorted([\n",
    "    os.path.join(IMAGE_DIR, f) for f in os.listdir(IMAGE_DIR)\n",
    "    if f.endswith('.jpg') and f in good_files\n",
    "])\n",
    "csv_mask_paths = sorted([\n",
    "    os.path.join(MASK_DIR, f) for f in os.listdir(MASK_DIR)\n",
    "    if f.endswith('.jpg') and f in good_files\n",
    "])\n",
    "\n",
    "print(f\"Total files in directory: {len(os.listdir(IMAGE_DIR))}\")\n",
    "print(f\"After CSV quality filter (quality != 'low'): {len(csv_image_paths)}\")\n",
    "\n",
    "valid_image_paths = []\n",
    "valid_mask_paths = []\n",
    "mask_stats = []\n",
    "removed_by_content = []\n",
    "'''\n",
    "for img_path, mask_path in zip(csv_image_paths, csv_mask_paths):\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    positive_ratio = (mask > 128).sum() / mask.size\n",
    "    \n",
    "    # Filter criteria: at least 0.5% positive pixels, max 50%\n",
    "    if 0.005 <= positive_ratio <= 0.5:\n",
    "        valid_image_paths.append(img_path)\n",
    "        valid_mask_paths.append(mask_path)\n",
    "        mask_stats.append(positive_ratio)\n",
    "    else:\n",
    "        removed_by_content.append((os.path.basename(img_path), positive_ratio))\n",
    "\n",
    "print(f\"After mask content filter (0.5% ≤ mask ≤ 50%): {len(valid_image_paths)}\")\n",
    "print(f\"  Removed by mask content: {len(removed_by_content)}\")\n",
    "'''\n",
    "# ============================================================================\n",
    "# SUMMARY\n",
    "# ============================================================================\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"FILTERING SUMMARY:\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Total files: {len(os.listdir(IMAGE_DIR))}\")\n",
    "print(f\"After CSV filter (quality != 'low'): {len(csv_image_paths)}\")\n",
    "print(f\"After mask content filter: {len(valid_image_paths)}\")\n",
    "print(f\"  ↳ Removed by CSV: {len(os.listdir(IMAGE_DIR)) - len(csv_image_paths)}\")\n",
    "print(f\"  ↳ Removed by mask content: {len(removed_by_content)}\")\n",
    "print(f\"Final dataset size: {len(valid_image_paths)}\")\n",
    "\n",
    "if mask_stats:\n",
    "    print(f\"\\nValid mask statistics:\")\n",
    "    print(f\"  Min: {min(mask_stats)*100:.2f}%\")\n",
    "    print(f\"  Max: {max(mask_stats)*100:.2f}%\")\n",
    "    print(f\"  Mean: {np.mean(mask_stats)*100:.2f}%\")\n",
    "    print(f\"  Median: {np.median(mask_stats)*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nFiles removed by mask content:\")\n",
    "for filename, ratio in removed_by_content:\n",
    "    reason = \"Empty mask\" if ratio < 0.005 else \"Too large (>50%)\"\n",
    "    print(f\"  {filename:40s} - {ratio*100:.2f}% ({reason})\")\n",
    "\n",
    "\n",
    "train_imgs, temp_imgs, train_masks, temp_masks = train_test_split(\n",
    "    csv_image_paths, csv_mask_paths, test_size=0.3, random_state=42\n",
    ")\n",
    "val_imgs, test_imgs, val_masks, test_masks = train_test_split(\n",
    "    temp_imgs, temp_masks, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"DATA SPLIT:\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Train: {len(train_imgs)} ({len(train_imgs)/len(csv_image_paths)*100:.1f}%)\")\n",
    "print(f\"Val:   {len(val_imgs)} ({len(val_imgs)/len(csv_image_paths)*100:.1f}%)\")\n",
    "print(f\"Test:  {len(test_imgs)} ({len(test_imgs)/len(csv_image_paths)*100:.1f}%)\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "steps_per_epoch = len(train_imgs) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34a05dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Checking first training sample ===\n",
      "Image shape: torch.Size([1, 198, 320]), range: [0.000, 0.980]\n",
      "Mask shape: torch.Size([1, 198, 320]), unique values: tensor([0., 1.])\n",
      "Mask positive ratio: 0.0453 (4.53%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/lanza/cvision/.venv/lib/python3.12/site-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Albumentations transforms\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(height=RESIZE_HEIGHT, width=IMAGE_SIZE),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=10, p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.GaussianBlur(blur_limit=(3, 5), p=0.3),\n",
    "    A.Normalize(mean=[0.0], std=[1.0]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(height=RESIZE_HEIGHT, width=IMAGE_SIZE),\n",
    "    A.Normalize(mean=[0.0], std=[1.0]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TrusDataset(train_imgs, train_masks, transform=train_transform)\n",
    "val_dataset = TrusDataset(val_imgs, val_masks, transform=val_transform)\n",
    "test_dataset = TrusDataset(test_imgs, test_masks, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "# Check first sample\n",
    "print(\"\\n=== Checking first training sample ===\")\n",
    "img, mask = train_dataset[0]\n",
    "print(f\"Image shape: {img.shape}, range: [{img.min():.3f}, {img.max():.3f}]\")\n",
    "print(f\"Mask shape: {mask.shape}, unique values: {mask.unique()}\")\n",
    "print(f\"Mask positive ratio: {mask.mean():.4f} ({100*mask.mean():.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279d2f28",
   "metadata": {},
   "source": [
    "Optuna tuning for hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be78f3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/lanza/cvision/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch.optim as optim\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-3)\n",
    "    alpha = trial.suggest_uniform('alpha', 0.1, 0.9)\n",
    "    dropout = trial.suggest_uniform('dropout', 0.0, 0.4)\n",
    "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.3)\n",
    "    weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
    "\n",
    "    # Rebuild model and optimizer\n",
    "    model = UNet(\n",
    "        in_channels=1,\n",
    "        out_channels=1,\n",
    "        features=[64, 128, 256, 512],\n",
    "        dropout=dropout,\n",
    "        deep_supervision=True,\n",
    "        use_se=True,\n",
    "        use_blurpool=True,\n",
    "        use_skip_refinement=True,\n",
    "        dropout_rate=dropout_rate\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    criterion = CombinedLoss(alpha=alpha, smooth=1e-6)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Train for a few epochs (e.g., 5 for speed)\n",
    "    best_val_dice = 0.0\n",
    "    for epoch in range(5):\n",
    "        model.train()\n",
    "        for images, masks in train_loader:\n",
    "            images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            if isinstance(outputs, tuple):\n",
    "                main_out, deep_outs = outputs\n",
    "                loss = criterion(main_out, masks)\n",
    "                for deep_out in deep_outs:\n",
    "                    deep_out_resized = F.interpolate(deep_out, size=masks.shape[2:])\n",
    "                    loss += 0.5 * criterion(deep_out_resized, masks)\n",
    "                outputs = main_out\n",
    "            else:\n",
    "                loss = criterion(outputs, masks)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_dice = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
    "                outputs = model(images)\n",
    "                if isinstance(outputs, tuple):\n",
    "                    outputs = outputs[0]\n",
    "                val_dice += dice_coefficient(outputs, masks).item()\n",
    "        avg_val_dice = val_dice / len(val_loader)\n",
    "        best_val_dice = max(best_val_dice, avg_val_dice)\n",
    "\n",
    "    return best_val_dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90fc6589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-18 22:45:05,459] A new study created in memory with name: no-name-cbea3ec6-e4c6-4bcf-8101-fe600c676565\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]/tmp/ipykernel_1131713/4289332344.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-3)\n",
      "/tmp/ipykernel_1131713/4289332344.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  alpha = trial.suggest_uniform('alpha', 0.1, 0.9)\n",
      "/tmp/ipykernel_1131713/4289332344.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout = trial.suggest_uniform('dropout', 0.0, 0.4)\n",
      "/tmp/ipykernel_1131713/4289332344.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.3)\n",
      "/tmp/ipykernel_1131713/4289332344.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
      "  0%|          | 0/20 [09:57<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-10-18 22:55:02,677] Trial 0 failed with parameters: {'lr': 0.0004891519654853065, 'alpha': 0.7542148133137595, 'dropout': 0.007976265987832765, 'dropout_rate': 0.036495017467315205, 'weight_decay': 4.582260283052538e-06} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/lanza/cvision/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1131713/4289332344.py\", line 34, in objective\n",
      "    outputs = model(images)\n",
      "              ^^^^^^^^^^^^^\n",
      "  File \"/users/lanza/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/lanza/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1131713/2509090337.py\", line 228, in forward\n",
      "    attn = self.attention_blocks[idx // 2](x, skip_connection)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/lanza/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/lanza/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1131713/2509090337.py\", line 72, in forward\n",
      "    psi = self.psi(psi)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/users/lanza/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/lanza/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/lanza/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py\", line 250, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/users/lanza/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/lanza/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/lanza/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py\", line 359, in forward\n",
      "    return torch.sigmoid(input)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-10-18 22:55:02,687] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptuna\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvisualization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plot_optimization_history\n\u001b[32m      3\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mBest trial:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m trial = study.best_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cvision/.venv/lib/python3.12/site-packages/optuna/study/study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cvision/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cvision/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cvision/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:258\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    251\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    254\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    255\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    256\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    257\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cvision/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m images, masks \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[32m     33\u001b[39m     images, masks = images.to(DEVICE), masks.to(DEVICE)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m     36\u001b[39m         main_out, deep_outs = outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 228\u001b[39m, in \u001b[36mUNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    224\u001b[39m     x = F.interpolate(x, size=skip_connection.shape[\u001b[32m2\u001b[39m:], \n\u001b[32m    225\u001b[39m                      mode=\u001b[33m'\u001b[39m\u001b[33mbilinear\u001b[39m\u001b[33m'\u001b[39m, align_corners=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    227\u001b[39m \u001b[38;5;66;03m# Spatial attention gate\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m attn = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention_blocks\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_connection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[38;5;66;03m# Refine skip connection if enabled\u001b[39;00m\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_skip_refinement:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 72\u001b[39m, in \u001b[36mAttentionBlock.forward\u001b[39m\u001b[34m(self, g, x)\u001b[39m\n\u001b[32m     70\u001b[39m x1 = \u001b[38;5;28mself\u001b[39m.W_x(x)\n\u001b[32m     71\u001b[39m psi = \u001b[38;5;28mself\u001b[39m.relu(g1 + x1)\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m psi = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpsi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpsi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x * psi\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:359\u001b[39m, in \u001b[36mSigmoid.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    356\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    357\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    358\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from optuna.visualization import plot_optimization_history\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20, show_progress_bar=True)\n",
    "\n",
    "print(\"\\nBest trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\" Dice Score: {trial.value}\")\n",
    "print(\" Params:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\" {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0d188ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Parameters: 36,188,465 / 36,188,465\n",
      "\n",
      "\n",
      "============================================================\n",
      "Starting Training\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 [Train]: 100%|██████████| 84/84 [03:35<00:00,  2.56s/it]\n",
      "Epoch 1/30 [Val]: 100%|██████████| 18/18 [00:10<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 — Train Loss: 2.0819, Train Dice: 0.2525, Val Loss: 0.5108, Val Dice: 0.3828, LR: 0.000100\n",
      "✓ Saved best model (Dice: 0.3828)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 [Train]: 100%|██████████| 84/84 [03:39<00:00,  2.62s/it]\n",
      "Epoch 2/30 [Val]: 100%|██████████| 18/18 [00:09<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 — Train Loss: 1.6669, Train Dice: 0.3186, Val Loss: 0.4660, Val Dice: 0.4305, LR: 0.000100\n",
      "✓ Saved best model (Dice: 0.4305)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 [Train]: 100%|██████████| 84/84 [03:39<00:00,  2.61s/it]\n",
      "Epoch 3/30 [Val]: 100%|██████████| 18/18 [00:09<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 — Train Loss: 1.4891, Train Dice: 0.3876, Val Loss: 0.4040, Val Dice: 0.5013, LR: 0.000100\n",
      "✓ Saved best model (Dice: 0.5013)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 [Train]: 100%|██████████| 84/84 [03:49<00:00,  2.73s/it]\n",
      "Epoch 4/30 [Val]: 100%|██████████| 18/18 [00:09<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 — Train Loss: 1.3984, Train Dice: 0.4206, Val Loss: 0.3607, Val Dice: 0.5549, LR: 0.000100\n",
      "✓ Saved best model (Dice: 0.5549)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 [Train]: 100%|██████████| 84/84 [03:41<00:00,  2.63s/it]\n",
      "Epoch 5/30 [Val]: 100%|██████████| 18/18 [00:09<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 — Train Loss: 1.3334, Train Dice: 0.4459, Val Loss: 0.3429, Val Dice: 0.5720, LR: 0.000100\n",
      "✓ Saved best model (Dice: 0.5720)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 [Train]: 100%|██████████| 84/84 [03:36<00:00,  2.58s/it]\n",
      "Epoch 6/30 [Val]: 100%|██████████| 18/18 [00:09<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 — Train Loss: 1.3082, Train Dice: 0.4618, Val Loss: 0.3334, Val Dice: 0.5861, LR: 0.000100\n",
      "✓ Saved best model (Dice: 0.5861)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 [Train]: 100%|██████████| 84/84 [03:44<00:00,  2.67s/it]\n",
      "Epoch 7/30 [Val]: 100%|██████████| 18/18 [00:09<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 — Train Loss: 1.2703, Train Dice: 0.4744, Val Loss: 0.3365, Val Dice: 0.5812, LR: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 [Train]: 100%|██████████| 84/84 [03:44<00:00,  2.68s/it]\n",
      "Epoch 8/30 [Val]: 100%|██████████| 18/18 [00:09<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 — Train Loss: 1.2530, Train Dice: 0.4839, Val Loss: 0.3413, Val Dice: 0.5707, LR: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 [Train]: 100%|██████████| 84/84 [03:42<00:00,  2.65s/it]\n",
      "Epoch 9/30 [Val]: 100%|██████████| 18/18 [00:10<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 — Train Loss: 1.2224, Train Dice: 0.4943, Val Loss: 0.3040, Val Dice: 0.6202, LR: 0.000100\n",
      "✓ Saved best model (Dice: 0.6202)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 [Train]: 100%|██████████| 84/84 [03:52<00:00,  2.77s/it]\n",
      "Epoch 10/30 [Val]: 100%|██████████| 18/18 [00:09<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 — Train Loss: 1.2095, Train Dice: 0.4989, Val Loss: 0.2953, Val Dice: 0.6319, LR: 0.000100\n",
      "✓ Saved best model (Dice: 0.6319)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 [Train]: 100%|██████████| 84/84 [03:50<00:00,  2.75s/it]\n",
      "Epoch 11/30 [Val]: 100%|██████████| 18/18 [00:12<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 — Train Loss: 1.1615, Train Dice: 0.5183, Val Loss: 0.3057, Val Dice: 0.6185, LR: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 [Train]: 100%|██████████| 84/84 [03:55<00:00,  2.80s/it]\n",
      "Epoch 12/30 [Val]: 100%|██████████| 18/18 [00:10<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 — Train Loss: 1.1555, Train Dice: 0.5246, Val Loss: 0.2941, Val Dice: 0.6322, LR: 0.000100\n",
      "✓ Saved best model (Dice: 0.6322)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 [Train]: 100%|██████████| 84/84 [04:22<00:00,  3.13s/it]\n",
      "Epoch 13/30 [Val]: 100%|██████████| 18/18 [00:10<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 — Train Loss: 1.1533, Train Dice: 0.5234, Val Loss: 0.2850, Val Dice: 0.6422, LR: 0.000100\n",
      "✓ Saved best model (Dice: 0.6422)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 [Train]: 100%|██████████| 84/84 [04:06<00:00,  2.94s/it]\n",
      "Epoch 14/30 [Val]: 100%|██████████| 18/18 [00:10<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 — Train Loss: 1.1545, Train Dice: 0.5247, Val Loss: 0.2835, Val Dice: 0.6456, LR: 0.000100\n",
      "✓ Saved best model (Dice: 0.6456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 [Train]:  35%|███▍      | 29/84 [01:26<02:44,  2.99s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 88\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[32m     87\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=\u001b[32m1.0\u001b[39m)\n\u001b[32m     91\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cvision/.venv/lib/python3.12/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cvision/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cvision/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# === Device ===\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 30 \n",
    "PATIENCE = 8  \n",
    "WEIGHT_DECAY = 1e-5\n",
    "LOSS_ALPHA = 0.3\n",
    "\n",
    "# === Model ===\n",
    "model = UNet(\n",
    "    in_channels=1, \n",
    "    out_channels=1,\n",
    "    features=[64, 128, 256, 512], \n",
    "    dropout=0.2, \n",
    "    deep_supervision=True, \n",
    "    use_se=True,\n",
    "    use_blurpool=True,\n",
    "    use_skip_refinement=True,\n",
    "    dropout_rate=0.1\n",
    ").to(DEVICE)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Model Parameters: {trainable_params:,} / {total_params:,}\\n\")\n",
    "\n",
    "\n",
    "# === Loss Function ===\n",
    "criterion = CombinedLoss(alpha=LOSS_ALPHA, smooth=1e-6)\n",
    "\n",
    "# === Optimizer ===\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# === Learning Rate Scheduler ===\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=3, min_lr=1e-6\n",
    ")\n",
    "\n",
    "# === Training State ===\n",
    "best_val_dice = 0.0\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_dices = []\n",
    "train_dices = []\n",
    "patience_counter = 0\n",
    "early_stop_patience = PATIENCE\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Starting Training\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # === Training Phase ===\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_dice = 0.0\n",
    "    \n",
    "    for images, masks in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\"):\n",
    "        images = images.to(DEVICE)\n",
    "        masks = masks.to(DEVICE)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Handle deep supervision outputs\n",
    "        if isinstance(outputs, tuple):\n",
    "            main_out, deep_outs = outputs\n",
    "            loss = criterion(main_out, masks)\n",
    "            \n",
    "            for deep_out in deep_outs:\n",
    "                \n",
    "                deep_out_resized = F.interpolate(\n",
    "                    deep_out, \n",
    "                    size=masks.shape[2:], \n",
    "                    mode='bilinear', \n",
    "                    align_corners=False\n",
    "                )\n",
    "                loss += 0.5 * criterion(deep_out_resized, masks)\n",
    "            outputs = main_out\n",
    "        else:\n",
    "            loss = criterion(outputs, masks)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_dice += dice_coefficient(outputs, masks).item()\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    avg_train_dice = train_dice / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_dices.append(avg_train_dice)\n",
    "    \n",
    "    # === Validation Phase ===\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_dice = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Val]\"):\n",
    "            images = images.to(DEVICE)\n",
    "            masks = masks.to(DEVICE)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Handle deep supervision outputs (disabled during eval)\n",
    "            if isinstance(outputs, tuple):\n",
    "                outputs = outputs[0]\n",
    "            \n",
    "            loss = criterion(outputs, masks)\n",
    "            dice = dice_coefficient(outputs, masks)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_dice += dice.item()\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    avg_val_dice = val_dice / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_dices.append(avg_val_dice)\n",
    "    \n",
    "    # === Learning Rate Scheduling ===\n",
    "    scheduler.step(avg_val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} — \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f}, \"\n",
    "          f\"Train Dice: {avg_train_dice:.4f}, \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}, \"\n",
    "          f\"Val Dice: {avg_val_dice:.4f}, \"\n",
    "          f\"LR: {current_lr:.6f}\")\n",
    "    \n",
    "    # === Save Best Model ===\n",
    "    if avg_val_dice > best_val_dice:\n",
    "        best_val_dice = avg_val_dice\n",
    "        patience_counter = 0\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_dice': best_val_dice,\n",
    "        }, 'SEBattention1.pth')\n",
    "        print(f\"✓ Saved best model (Dice: {best_val_dice:.4f})\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= early_stop_patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "            break\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Training completed! Best Val Dice: {best_val_dice:.4f}\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5d42978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_list = list(range(1, len(train_losses) + 1))  # or use len(val_dice) if that's more reliable\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_list, train_losses, label='Training Loss')\n",
    "plt.plot(epochs_list, val_losses, label='Validation Loss')\n",
    "plt.xticks(ticks=epochs_list)\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Plot Dice\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_list, train_dices, label='Training Dice')\n",
    "plt.plot(epochs_list, val_dices, label='Validation Dice')\n",
    "plt.xticks(ticks=epochs_list)\n",
    "plt.title('Dice Coefficient over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Dice')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ac8d598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating on Test Set ===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m masks = masks.to(DEVICE)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Handle deep supervision (should only return main output in eval mode)\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mtuple\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 210\u001b[39m, in \u001b[36mUNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    207\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.pools[i](x)\n\u001b[32m    209\u001b[39m \u001b[38;5;66;03m# Bottleneck\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbottleneck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[38;5;66;03m# Reverse skip connections\u001b[39;00m\n\u001b[32m    213\u001b[39m skip_connections = skip_connections[::-\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 141\u001b[39m, in \u001b[36mDilatedDoubleConv.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cvision/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:144\u001b[39m, in \u001b[36mReLU.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    141\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    142\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cvision/.venv/lib/python3.12/site-packages/torch/nn/functional.py:1695\u001b[39m, in \u001b[36mrelu\u001b[39m\u001b[34m(input, inplace)\u001b[39m\n\u001b[32m   1693\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(relu, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, inplace=inplace)\n\u001b[32m   1694\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m-> \u001b[39m\u001b[32m1695\u001b[39m     result = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrelu_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1696\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1697\u001b[39m     result = torch.relu(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Evaluating on Test Set ===\")\n",
    "\n",
    "# Load the best model\n",
    "checkpoint = torch.load('SEBattention1.pth', map_location=DEVICE)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Instantiate loss criterion once\n",
    "criterion = CombinedLoss(alpha=0.5, smooth=1e-6)\n",
    "\n",
    "test_dice = 0.0\n",
    "test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, masks in test_loader:\n",
    "        images = images.to(DEVICE)\n",
    "        masks = masks.to(DEVICE)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Handle deep supervision (should only return main output in eval mode)\n",
    "        if isinstance(outputs, tuple):\n",
    "            outputs = outputs[0]\n",
    "        \n",
    "        # Calculate loss and dice\n",
    "        loss = criterion(outputs, masks)\n",
    "        dice = dice_coefficient(outputs, masks)\n",
    "        \n",
    "        test_loss += loss.item()\n",
    "        test_dice += dice.item()\n",
    "\n",
    "avg_test_dice = test_dice / len(test_loader)\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "print(f\"Test Dice: {avg_test_dice:.4f}\")\n",
    "print(f\"\\n{'='*60}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
