{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59ec3e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /users/lanza/cvision/Polyps/Kvasir-SEG\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "os.chdir(\"/users/lanza/cvision/Polyps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee92b9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import yaml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a23e4db",
   "metadata": {},
   "source": [
    "\n",
    "# PART 1: DATASET CONVERTER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "098c3b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KvasirToYOLO:\n",
    "    \"\"\"Convert Kvasir JSON bbox format to YOLO format with train/val/test support.\"\"\"\n",
    "\n",
    "    def __init__(self, image_dir, json_path, output_dir, seed=42):\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.json_path = Path(json_path)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.seed = seed\n",
    "\n",
    "        with open(self.json_path, 'r') as f:\n",
    "            self.annotations = json.load(f)\n",
    "\n",
    "        if not isinstance(self.annotations, dict):\n",
    "            raise ValueError(\"Annotations JSON must be a dict keyed by image ID.\")\n",
    "\n",
    "        self._has_test_split = False\n",
    "\n",
    "    @staticmethod\n",
    "    def _voc_to_yolo_bbox(bbox, img_width, img_height):\n",
    "        \"\"\"Convert Pascal VOC bbox to YOLO format with validation.\"\"\"\n",
    "        xmin = float(bbox['xmin'])\n",
    "        ymin = float(bbox['ymin'])\n",
    "        xmax = float(bbox['xmax'])\n",
    "        ymax = float(bbox['ymax'])\n",
    "\n",
    "        # Clamp to image bounds\n",
    "        xmin = max(0.0, min(xmin, img_width - 1))\n",
    "        ymin = max(0.0, min(ymin, img_height - 1))\n",
    "        xmax = max(0.0, min(xmax, img_width - 1))\n",
    "        ymax = max(0.0, min(ymax, img_height - 1))\n",
    "\n",
    "        # Skip invalid boxes\n",
    "        if xmax <= xmin or ymax <= ymin:\n",
    "            return None\n",
    "\n",
    "        x_center = (xmin + xmax) / 2.0\n",
    "        y_center = (ymin + ymax) / 2.0\n",
    "        width = xmax - xmin\n",
    "        height = ymax - ymin\n",
    "\n",
    "        # Normalize\n",
    "        x_center /= img_width\n",
    "        y_center /= img_height\n",
    "        width /= img_width\n",
    "        height /= img_height\n",
    "\n",
    "        # Final clamps\n",
    "        x_center = max(0.0, min(1.0, x_center))\n",
    "        y_center = max(0.0, min(1.0, y_center))\n",
    "        width = max(1e-6, min(1.0, width))\n",
    "        height = max(1e-6, min(1.0, height))\n",
    "        # Return YOLO line as [class_id, x, y, w, h]; class_id is hardcoded 0 for 'polyp'\n",
    "        return [0, x_center, y_center, width, height]\n",
    "\n",
    "    def prepare_dataset(self, train_split=0.8, val_split=None, test_split=None, create_empty_labels=True):\n",
    "        \"\"\"Prepare dataset with train/val/test splits.\"\"\"\n",
    "        \n",
    "        # Validate splits\n",
    "        for name, v in [('train_split', train_split), ('val_split', val_split), \n",
    "                       ('test_split', test_split)]:\n",
    "            if v is not None and not (0.0 <= v <= 1.0):\n",
    "                raise ValueError(f\"{name} must be in [0, 1].\")\n",
    "            if train_split + (val_split or 0) + (test_split or 0) > 1.0 + 1e-8:\n",
    "                raise ValueError(\"Sum of split fractions cannot exceed 1.0\")\n",
    "\n",
    "\n",
    "        if val_split is None and test_split is not None:\n",
    "            raise ValueError(\"If you set test_split, you must also set val_split.\")\n",
    "\n",
    "        if val_split is None:\n",
    "            val = 1.0 - train_split\n",
    "            test = 0.0\n",
    "        else:\n",
    "            if test_split is None:\n",
    "                remaining = 1.0 - (train_split + val_split)\n",
    "                val = val_split\n",
    "                test = max(0.0, remaining)\n",
    "            else:\n",
    "                val = val_split\n",
    "                test = test_split\n",
    "\n",
    "        self._has_test_split = test > 0.0 + 1e-9\n",
    "\n",
    "        # Create directories\n",
    "        dirs = {\n",
    "            'train_images': self.output_dir / 'images' / 'train',\n",
    "            'val_images':   self.output_dir / 'images' / 'val',\n",
    "            'train_labels': self.output_dir / 'labels' / 'train',\n",
    "            'val_labels':   self.output_dir / 'labels' / 'val',\n",
    "        }\n",
    "        if self._has_test_split:\n",
    "            dirs.update({\n",
    "                'test_images': self.output_dir / 'images' / 'test',\n",
    "                'test_labels': self.output_dir / 'labels' / 'test',\n",
    "            })\n",
    "        for d in dirs.values():\n",
    "            d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Shuffle and split\n",
    "        image_ids = list(self.annotations.keys())\n",
    "        rnd = random.Random(self.seed)\n",
    "        rnd.shuffle(image_ids)\n",
    "\n",
    "        # Compute split counts\n",
    "        n = len(image_ids)\n",
    "        n_train = int(n * train_split)  # floor by int()\n",
    "        n_val = int(n * val)            # floor by int()\n",
    "        # Test gets the remainder so that train+val+test sums exactly to n\n",
    "        n_test = n - n_train - n_val if self._has_test_split else 0\n",
    "\n",
    "        train_ids = image_ids[:n_train]\n",
    "        val_ids   = image_ids[n_train:n_train + n_val]\n",
    "        test_ids  = image_ids[n_train + n_val:] if self._has_test_split else []\n",
    "\n",
    "        print(f\"Processing images: total={n} | train={len(train_ids)}, \"\n",
    "              f\"val={len(val_ids)}\" + (f\", test={len(test_ids)}\" if self._has_test_split else \"\"))\n",
    "\n",
    "        # Process splits\n",
    "        self._process_split(train_ids, dirs['train_images'], dirs['train_labels'], \n",
    "                          create_empty_labels)\n",
    "        self._process_split(val_ids, dirs['val_images'], dirs['val_labels'], \n",
    "                          create_empty_labels)\n",
    "        if self._has_test_split:\n",
    "            self._process_split(test_ids, dirs['test_images'], dirs['test_labels'], \n",
    "                              create_empty_labels)\n",
    "\n",
    "        # Create YAML\n",
    "        self._create_yaml()\n",
    "\n",
    "        print(\"\\n✓ Dataset prepared successfully!\")\n",
    "        print(f\"  Output: {self.output_dir.resolve()}\")\n",
    "        print(f\"  Train:  {len(train_ids)} images\")\n",
    "        print(f\"  Val:    {len(val_ids)} images\")\n",
    "        if self._has_test_split:\n",
    "            print(f\"  Test:   {len(test_ids)} images\")\n",
    "\n",
    "    def _process_split(self, image_ids, img_dir, label_dir, create_empty_labels=True):\n",
    "        \"\"\"Process images for a specific split.\"\"\"\n",
    "        for img_id in image_ids:\n",
    "            img_path = self.image_dir / f\"{img_id}.jpg\"\n",
    "            if not img_path.exists():\n",
    "                img_path = self.image_dir / f\"{img_id}.png\"\n",
    "            if not img_path.exists():\n",
    "                print(f\"Warning: Image not found for {img_id}\")\n",
    "                continue\n",
    "\n",
    "            with Image.open(img_path) as img:\n",
    "                img_width, img_height = img.size\n",
    "\n",
    "            shutil.copy(img_path, img_dir / img_path.name)\n",
    "\n",
    "            annotation = self.annotations.get(img_id, {})\n",
    "            bboxes = annotation.get('bbox', [])\n",
    "\n",
    "            yolo_lines = []\n",
    "            for bbox in bboxes:\n",
    "                yolo_bbox = self._voc_to_yolo_bbox(bbox, img_width, img_height)\n",
    "                if yolo_bbox is not None:\n",
    "                    line = ' '.join(f\"{v:.6f}\" if i > 0 else str(int(v))\n",
    "                                   for i, v in enumerate(yolo_bbox))\n",
    "                    yolo_lines.append(line)\n",
    "\n",
    "            label_path = label_dir / f\"{img_path.stem}.txt\"\n",
    "            if yolo_lines:\n",
    "                with open(label_path, 'w') as f:\n",
    "                    f.write('\\n'.join(yolo_lines) + '\\n')\n",
    "            else:\n",
    "                if create_empty_labels:\n",
    "                    open(label_path, 'a').close()\n",
    "\n",
    "    def _create_yaml(self):\n",
    "        \"\"\"Create data.yaml configuration file.\"\"\"\n",
    "        data = {\n",
    "            'path': str(self.output_dir.resolve()),\n",
    "            'train': 'images/train',\n",
    "            'val': 'images/val',\n",
    "            'nc': 1,\n",
    "            'names': ['polyp'],\n",
    "        }\n",
    "        if self._has_test_split:\n",
    "            data['test'] = 'images/test'\n",
    "\n",
    "        yaml_path = self.output_dir / 'data.yaml'\n",
    "        with open(yaml_path, 'w') as f:\n",
    "            yaml.dump(data, f, default_flow_style=False)\n",
    "        print(f\"  Created: {yaml_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f5c915",
   "metadata": {},
   "source": [
    "# PART 2: AUTOMATIC LEARNING RATE FINDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71409526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def auto_find_best_lr(\n",
    "    data_yaml_path,\n",
    "    model_size='n',\n",
    "    img_size=640,\n",
    "    batch_size=8,\n",
    "    epochs=20,\n",
    "    test_lr0_values=None,\n",
    "    project='runs/lr_finder',\n",
    "    weight_score_map50=0.7,\n",
    "    weight_score_recall=0.3\n",
    "):\n",
    "    \"\"\"\n",
    "    Automatically find the best learning rate by testing multiple values.\n",
    "    Returns the lr0 that gives best performance (weighted mAP50 + Recall).\n",
    "    \"\"\"\n",
    "\n",
    "    # Safer default for mutable arg\n",
    "    if test_lr0_values is None:\n",
    "        test_lr0_values = [1e-4, 1e-3, 5e-3, 1e-2, 5e-2]\n",
    "\n",
    "    # Device detection\n",
    "    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        device = 'mps'\n",
    "        print(\"Using Apple Silicon GPU (MPS)\")\n",
    "    elif torch.cuda.is_available():\n",
    "        device = 0\n",
    "        print(\"Using NVIDIA GPU (CUDA)\")\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "        print(\"Using CPU\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"AUTOMATIC LEARNING RATE FINDER\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Testing {len(test_lr0_values)} learning rates...\")\n",
    "    print(f\"Device: {device}\")\n",
    "    print(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "    # Show grid explicitly (helps debug)\n",
    "    print(\"LR grid:\", [f\"{float(v):.6g}\" for v in test_lr0_values])\n",
    "\n",
    "    results_data = []\n",
    "\n",
    "    for idx, lr0_value in enumerate(test_lr0_values, start=1):\n",
    "        lr0_value = float(lr0_value)\n",
    "        run_name = f'lr_test_{idx:02d}_{lr0_value:.6g}'\n",
    "        print(f\"[{idx}/{len(test_lr0_values)}] → Testing lr0 = {lr0_value:.6g} (run: {run_name})...\", flush=True)\n",
    "\n",
    "        # Fresh model per trial\n",
    "        model = YOLO(f'yolov8{model_size}.pt')\n",
    "\n",
    "        # Default failed values in case of early exception\n",
    "        map50 = 0.0\n",
    "        recall = 0.0\n",
    "        score = 0.0\n",
    "        run_dir = Path(project) / run_name\n",
    "\n",
    "        try:\n",
    "            # Train with this LR (force optimizer so lr0 is respected)\n",
    "            model.train(\n",
    "                data=data_yaml_path,\n",
    "                epochs=epochs,\n",
    "                imgsz=img_size,\n",
    "                batch=batch_size,\n",
    "                lr0=lr0_value,\n",
    "                lrf=0.1,\n",
    "                optimizer='AdamW',       # critical: avoid optimizer='auto'\n",
    "                warmup_epochs=2,\n",
    "                patience=999,\n",
    "                name=run_name,\n",
    "                project=project,\n",
    "                exist_ok=True,\n",
    "                verbose=False,\n",
    "                mosaic=0.0,\n",
    "                mixup=0.0,\n",
    "                flipud=0.5,\n",
    "                fliplr=0.5,\n",
    "                seed=0,\n",
    "                device=device,\n",
    "            )\n",
    "\n",
    "            # Load best weights\n",
    "            best_weights = run_dir / 'weights' / 'best.pt'\n",
    "            if not best_weights.exists():\n",
    "                raise FileNotFoundError(f\"best.pt not found at {best_weights}\")\n",
    "\n",
    "            best_model = YOLO(str(best_weights))\n",
    "\n",
    "            # Validate with your desired thresholds\n",
    "            # NOTE: arg names are 'conf' and 'iou' per Ultralytics API\n",
    "            val_metrics = best_model.val(\n",
    "                data=data_yaml_path,\n",
    "                imgsz=img_size,\n",
    "                batch=batch_size,\n",
    "                device=device,\n",
    "                verbose=False,\n",
    "                save=False  \n",
    "            )\n",
    "\n",
    "            # Extract metrics safely\n",
    "            map50 = float(getattr(val_metrics.box, 'map50', 0.0))\n",
    "\n",
    "            r = getattr(val_metrics.box, 'r', None)\n",
    "            if r is not None:\n",
    "                try:\n",
    "                    recall = float(np.mean(r)) if hasattr(r, '__len__') else float(r)\n",
    "                except Exception:\n",
    "                    recall = 0.0\n",
    "            if recall == 0.0:\n",
    "                rd = getattr(val_metrics, 'results_dict', {}) or {}\n",
    "                recall = float(rd.get('metrics/recall(B)', 0.0))\n",
    "\n",
    "            # Composite score\n",
    "            score = weight_score_map50 * map50 + weight_score_recall * recall\n",
    "\n",
    "            print(f\"  mAP@0.50: {map50:.4f} | Recall: {recall:.4f} | Score: {score:.4f}\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Failed: {e}\\n\")\n",
    "\n",
    "        finally:\n",
    "            # Free memory between trials\n",
    "            try:\n",
    "                del model\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                del best_model\n",
    "            except:\n",
    "                pass\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            # Append exactly once per trial (either real numbers or zeros)\n",
    "            results_data.append({\n",
    "                'lr0': lr0_value,\n",
    "                'map50': map50,\n",
    "                'recall': recall,\n",
    "                'score': score,\n",
    "                'run_dir': str(run_dir)\n",
    "            })\n",
    "\n",
    "    # ---- Determine best ----\n",
    "    valid_results = [r for r in results_data if r['score'] > 0.0]\n",
    "    if not valid_results:\n",
    "        raise RuntimeError(\"No valid results produced; check your data and settings.\")\n",
    "\n",
    "    best_result = max(valid_results, key=lambda x: x['score'])\n",
    "    best_lr0 = best_result['lr0']\n",
    "\n",
    "    # ---- Plot results ----\n",
    "    lr0_values = [r['lr0'] for r in valid_results]\n",
    "    scores = [r['score'] for r in valid_results]\n",
    "    maps = [r['map50'] for r in valid_results]\n",
    "    recalls = [r['recall'] for r in valid_results]\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    ax1.semilogx(lr0_values, scores, 'o-', linewidth=2, markersize=10, color='#3498db')\n",
    "    ax1.axvline(best_lr0, color='red', linestyle='--', linewidth=2, label=f'Best lr0: {best_lr0:g}')\n",
    "    ax1.set_xlabel('Initial Learning Rate (lr0)', fontsize=12)\n",
    "    ax1.set_ylabel('Composite Score', fontsize=12)\n",
    "    ax1.set_title('Learning Rate Performance', fontsize=14, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.semilogx(lr0_values, maps, 'o-', linewidth=2, label='mAP@0.50', color='#2ecc71')\n",
    "    ax2.semilogx(lr0_values, recalls, 's-', linewidth=2, label='Recall', color='#e74c3c')\n",
    "    ax2.axvline(best_lr0, color='red', linestyle='--', linewidth=2, alpha=0.5)\n",
    "    ax2.set_xlabel('Initial Learning Rate (lr0)', fontsize=12)\n",
    "    ax2.set_ylabel('Metric Value', fontsize=12)\n",
    "    ax2.set_title('mAP vs Recall', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('lr_finder_results.png', dpi=150, bbox_inches='tight')\n",
    "    print(f\"\\n📊 Plot saved: lr_finder_results.png\")\n",
    "\n",
    "    # ---- Summary ----\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"LR FINDER RESULTS\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\n🎯 BEST INITIAL LEARNING RATE (lr0): {best_lr0:g}\")\n",
    "    print(f\"   mAP@0.50: {best_result['map50']:.4f}\")\n",
    "    print(f\"   Recall:   {best_result['recall']:.4f}\")\n",
    "    print(f\"   Score:    {best_result['score']:.4f}\")\n",
    "\n",
    "    print(\"\\n📋 All Results:\")\n",
    "    print(f\"{'lr0':<12} {'mAP@0.50':<12} {'Recall':<12} {'Score':<12} {'Run'}\")\n",
    "    print(\"-\" * 70)\n",
    "    for r in sorted(valid_results, key=lambda x: x['score'], reverse=True):\n",
    "        marker = \"⭐\" if r['lr0'] == best_lr0 else \"  \"\n",
    "        print(f\"{marker} {r['lr0']:<10.6f} {r['map50']:<12.4f} {r['recall']:<12.4f} {r['score']:<12.4f} {r['run_dir']}\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    return best_lr0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904a7935",
   "metadata": {},
   "source": [
    "# PART 3: TRAINING, EVALUATION, AND INFERENCE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd35570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_yolo(data_yaml_path, model_size='n', epochs=100, img_size=640, \n",
    "               batch_size=8, workers=4, lr0=0.01):\n",
    "    \"\"\"Train YOLOv8 model with medical-optimized settings.\"\"\"\n",
    "    \n",
    "    # Device detection\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = 'mps'\n",
    "        print(\"Using Apple Silicon GPU (MPS)\")\n",
    "    elif torch.cuda.is_available():\n",
    "        device = 0\n",
    "        print(\"Using NVIDIA GPU (CUDA)\")\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "        print(\"Using CPU\")\n",
    "\n",
    "    model = YOLO(f'yolov8{model_size}.pt')\n",
    "\n",
    "    results = model.train(\n",
    "        data=data_yaml_path,\n",
    "        epochs=epochs,\n",
    "        imgsz=img_size,\n",
    "        batch=batch_size,\n",
    "        name='polyp_detection',\n",
    "        patience=20,\n",
    "        save=True,\n",
    "        device=device,\n",
    "        workers=workers,\n",
    "        optimizer='AdamW',\n",
    "        \n",
    "        # Learning rate settings\n",
    "        lr0=lr0,\n",
    "        lrf=0.1,\n",
    "        cos_lr = True,\n",
    "        warmup_epochs=5,\n",
    "        warmup_momentum=0.8,\n",
    "        momentum=0.937,\n",
    "        weight_decay=0.001,\n",
    "        dropout=0.1,\n",
    "        multi_scale=True,\n",
    "        # Medical imaging augmentations\n",
    "        mosaic=0.0,\n",
    "        mixup=0.0,\n",
    "        copy_paste=0.0,\n",
    "        erasing=0.0,\n",
    "        hsv_h=0.015,\n",
    "        hsv_s=0.3,\n",
    "        hsv_v=0.3,\n",
    "        degrees=10.0,\n",
    "        translate=0.1,\n",
    "        scale=0.2,\n",
    "        perspective=0.0,\n",
    "        shear=0.0,\n",
    "        flipud=0.5,  # Enabled for endoscopy\n",
    "        fliplr=0.5,\n",
    "        augment= True,\n",
    "        auto_augment = 'randaugment',\n",
    "        copy_paste = 0.1,\n",
    "        mixup =  0.1,       \n",
    "        erasing =  0.2,     \n",
    "        blur = 0.01,\n",
    "        noise = 0.02\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model_path, data_yaml_path, split='val'):\n",
    "    \"\"\"Evaluate trained model on validation or test split.\"\"\"\n",
    "    model = YOLO(model_path)\n",
    "    \n",
    "    if split not in ('val', 'test'):\n",
    "        raise ValueError(\"split must be 'val' or 'test'\")\n",
    "\n",
    "    metrics = model.val(data=data_yaml_path, split=split, conf= 0.5, iou=0.5)\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"EVALUATION RESULTS ON {split.upper()} SET\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    try:\n",
    "        print(f\"mAP@0.50     : {metrics.box.map50:.4f}\")\n",
    "        print(f\"mAP@0.50:0.95: {metrics.box.map:.4f}\")\n",
    "        if hasattr(metrics.box, 'p') and len(metrics.box.p) > 0:\n",
    "            print(f\"Precision    : {metrics.box.p[0]:.4f}\")\n",
    "        if hasattr(metrics.box, 'r') and len(metrics.box.r) > 0:\n",
    "            print(f\"Recall       : {metrics.box.r[0]:.4f}\")\n",
    "        print(\"=\"*70)\n",
    "    except Exception as e:\n",
    "        print(f\"Note: Metric structure changed: {e}\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def predict_and_visualize(model_path, image_path, conf_threshold=0.5):\n",
    "    \"\"\"Run inference and visualize results.\"\"\"\n",
    "    model = YOLO(model_path)\n",
    "    results = model(image_path, conf=conf_threshold, iou=0.5)\n",
    "\n",
    "    for result in results:\n",
    "        img_with_boxes = result.plot()\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Polyp Detection (confidence > {conf_threshold})', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        if hasattr(result, 'boxes') and len(result.boxes) > 0:\n",
    "            print(f\"\\n✓ Detected {len(result.boxes)} polyp(s):\")\n",
    "            for i, box in enumerate(result.boxes):\n",
    "                if hasattr(box, 'conf'):\n",
    "                    conf = float(box.conf[0].item())\n",
    "                    print(f\"  Polyp {i+1}: confidence = {conf:.3f}\")\n",
    "        else:\n",
    "            print(\"\\n✓ No polyps detected\")\n",
    "\n",
    "def predict_on_all_images(model_path, image_dir, data_yaml_path=None, conf_threshold=0.5, save_dir='predictions'):\n",
    "    \"\"\"\n",
    "    Run inference on all images in a directory, save results, and compute detailed statistics.\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to trained model\n",
    "        image_dir: Directory with test or val images\n",
    "        data_yaml_path: Optional path to data.yaml for mAP evaluation\n",
    "        conf_threshold: Confidence threshold\n",
    "        save_dir: Directory to save prediction images\n",
    "    \"\"\"\n",
    "    from pathlib import Path\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    from ultralytics import YOLO\n",
    "\n",
    "    model = YOLO(model_path)\n",
    "    image_dir = Path(image_dir)\n",
    "    save_dir = Path(save_dir)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    label_dir = image_dir.parent.parent / 'labels' / image_dir.name\n",
    "    image_files = list(image_dir.glob(\"*.jpg\")) + list(image_dir.glob(\"*.png\"))\n",
    "\n",
    "    if not image_files:\n",
    "        print(f\"No images found in {image_dir}\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"RUNNING INFERENCE ON ALL {len(image_files)} IMAGES\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    total_gt_polyps = 0\n",
    "    total_pred_polyps = 0\n",
    "    images_with_polyps = 0\n",
    "\n",
    "    TP = FP = FN = TN = 0\n",
    "\n",
    "    for img_path in image_files:\n",
    "        label_path = label_dir / f\"{img_path.stem}.txt\"\n",
    "        if label_path.exists():\n",
    "            with open(label_path, 'r') as f:\n",
    "                gt_boxes = [line for line in f if line.strip()]\n",
    "                num_gt = len(gt_boxes)\n",
    "        else:\n",
    "            num_gt = 0\n",
    "\n",
    "        results = model(str(img_path), conf=conf_threshold, iou=0.5, verbose=False)\n",
    "\n",
    "        for result in results:\n",
    "            img_with_boxes = result.plot()\n",
    "            output_path = save_dir / f\"pred_{img_path.name}\"\n",
    "            cv2.imwrite(str(output_path), img_with_boxes)\n",
    "\n",
    "            if hasattr(result, 'boxes') and len(result.boxes) > 0:\n",
    "                num_pred = len(result.boxes)\n",
    "                total_pred_polyps += num_pred\n",
    "                images_with_polyps += 1\n",
    "                print(f\"✓ {img_path.name}: {num_pred} polyp(s)\")\n",
    "            else:\n",
    "                num_pred = 0\n",
    "                print(f\"  {img_path.name}: No polyps detected\")\n",
    "\n",
    "            # Contingency matrix update\n",
    "            if num_gt > 0 and num_pred > 0:\n",
    "                TP += 1\n",
    "            elif num_gt == 0 and num_pred > 0:\n",
    "                FP += 1\n",
    "            elif num_gt > 0 and num_pred == 0:\n",
    "                FN += 1\n",
    "            elif num_gt == 0 and num_pred == 0:\n",
    "                TN += 1\n",
    "\n",
    "            total_gt_polyps += num_gt\n",
    "\n",
    "    # Compute metrics\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "    f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "    # mAP evaluation\n",
    "    map50 = map5095 = None\n",
    "    if data_yaml_path:\n",
    "        metrics = model.val(data=data_yaml_path, split=image_dir.name, conf=conf_threshold, iou=0.5)\n",
    "        map50 = float(getattr(metrics.box, 'map50', 0.0))\n",
    "        map5095 = float(getattr(metrics.box, 'map', 0.0))\n",
    "\n",
    "    # Summary\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"INFERENCE SUMMARY\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Total images:           {len(image_files)}\")\n",
    "    print(f\"Images with polyps:     {images_with_polyps}\")\n",
    "    print(f\"Images without polyps:  {len(image_files) - images_with_polyps}\")\n",
    "    print(f\"Total ground truth polyps: {total_gt_polyps}\")\n",
    "    print(f\"Total predicted polyps:    {total_pred_polyps}\")\n",
    "    print(f\"\\nContingency Matrix (image-level):\")\n",
    "    print(f\"  TP (GT & Pred):        {TP}\")\n",
    "    print(f\"  FP (No GT, Pred):      {FP}\")\n",
    "    print(f\"  FN (GT, No Pred):      {FN}\")\n",
    "    print(f\"  TN (No GT, No Pred):   {TN}\")\n",
    "    print(f\"\\nPrecision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-score:  {f1_score:.4f}\")\n",
    "    if map50 is not None:\n",
    "        print(f\"mAP@0.50:     {map50:.4f}\")\n",
    "        print(f\"mAP@0.50–0.95:{map5095:.4f}\")\n",
    "    print(f\"\\nPredictions saved to:   {save_dir.resolve()}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    \n",
    "\n",
    "def export_model(model_path, format='onnx'):\n",
    "    \"\"\"Export model to different formats.\"\"\"\n",
    "    model = YOLO(model_path)\n",
    "    model.export(format=format)\n",
    "    print(f\"✓ Model exported to {format} format\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8548a13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\": # Main execution block, no automatic run on import\n",
    "    SEED = 42\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "    # ========== CONFIGURATION ==========\n",
    "    IMAGE_DIR = \"Kvasir-SEG/images\"\n",
    "    JSON_PATH = \"Kvasir-SEG/kavsir_bboxes.json\"\n",
    "    OUTPUT_DIR = \"kvasir_yolo_dataset\"\n",
    "    MODEL_SIZE = 'm'  # 'n', 's', 'm', 'l', 'x'\n",
    "    BATCH_SIZE = 8\n",
    "    EPOCHS = 30\n",
    "    DATA_YAML = f\"{OUTPUT_DIR}/data.yaml\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77247965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 1: DATASET PREPARATION\n",
      "======================================================================\n",
      "Processing images: total=1000 | train=700, val=200, test=100\n",
      "  Created: kvasir_yolo_dataset/data.yaml\n",
      "\n",
      "✓ Dataset prepared successfully!\n",
      "  Output: /users/lanza/cvision/Polyps/kvasir_yolo_dataset\n",
      "  Train:  700 images\n",
      "  Val:    200 images\n",
      "  Test:   100 images\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":   \n",
    "    \n",
    "    # ========== STEP 1: Dataset Preparation ==========\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STEP 1: DATASET PREPARATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if not os.path.isdir(IMAGE_DIR):\n",
    "        print(f\"[ERROR] IMAGE_DIR not found: {IMAGE_DIR}\")\n",
    "        sys.exit(1)\n",
    "    if not os.path.isfile(JSON_PATH):\n",
    "        print(f\"[ERROR] JSON_PATH not found: {JSON_PATH}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    converter = KvasirToYOLO(IMAGE_DIR, JSON_PATH, OUTPUT_DIR, seed=SEED)\n",
    "    converter.prepare_dataset(train_split=0.7, val_split=0.2, test_split=0.1)  # 70/20/10 split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724681c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 1: DATASET PREPARATION\n",
      "======================================================================\n",
      "Processing images: total=1000 | train=700, val=200, test=100\n",
      "  Created: kvasir_yolo_dataset/data.yaml\n",
      "\n",
      "✓ Dataset prepared successfully!\n",
      "  Output: /users/lanza/cvision/Polyps/kvasir_yolo_dataset\n",
      "  Train:  700 images\n",
      "  Val:    200 images\n",
      "  Test:   100 images\n",
      "\n",
      "======================================================================\n",
      "STEP 2: FINDING BEST LEARNING RATE\n",
      "======================================================================\n",
      "Using CPU\n",
      "\n",
      "======================================================================\n",
      "AUTOMATIC LEARNING RATE FINDER\n",
      "======================================================================\n",
      "Testing 6 learning rates...\n",
      "Device: cpu\n",
      "======================================================================\n",
      "\n",
      "LR grid: ['1e-05', '0.0001', '0.001', '0.005', '0.01', '0.05']\n",
      "[1/6] → Testing lr0 = 1e-05 (run: lr_test_01_1e-05)...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m.pt to 'yolov8m.pt': 100% ━━━━━━━━━━━━ 49.7MB 66.6MB/s 0.7s 0.7s<0.0s\n",
      "Ultralytics 8.3.217 🚀 Python-3.12.3 torch-2.9.0+cu128 CPU (Intel Xeon Gold 6252 CPU @ 2.10GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=kvasir_yolo_dataset/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.5, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=1e-05, lrf=0.1, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=lr_test_01_1e-05, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=999, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/lr_finder, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/users/lanza/cvision/Polyps/runs/lr_finder/lr_test_01_1e-05, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=2, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
      "Model summary: 169 layers, 25,856,899 parameters, 25,856,883 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 106.0±42.8 MB/s, size: 28.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /users/lanza/cvision/Polyps/kvasir_yolo_dataset/labels/train... 700 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 700/700 851.5it/s 0.8s0.2s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /users/lanza/cvision/Polyps/kvasir_yolo_dataset/labels/train.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 9.0±2.9 MB/s, size: 37.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /users/lanza/cvision/Polyps/kvasir_yolo_dataset/labels/val... 200 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 200/200 1.2Kit/s 0.2s<0.2s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /users/lanza/cvision/Polyps/kvasir_yolo_dataset/labels/val.cache\n",
      "Plotting labels to /users/lanza/cvision/Polyps/runs/lr_finder/lr_test_01_1e-05/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=1e-05, momentum=0.937) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/users/lanza/cvision/Polyps/runs/lr_finder/lr_test_01_1e-05\u001b[0m\n",
      "Starting training for 15 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/15         0G     0.8715      1.272      1.325          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:313.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 33.6s2.9s\n",
      "                   all        200        216      0.753      0.606      0.709      0.529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/15         0G     0.7533     0.9221       1.22          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:263.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 31.3s2.5s\n",
      "                   all        200        216       0.82      0.759      0.863      0.683\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/15         0G     0.7155       0.83      1.195          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:223.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 36.0s2.8s\n",
      "                   all        200        216      0.854      0.759       0.88      0.712\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/15         0G     0.6829     0.7793      1.152          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:224.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 32.3s2.6s\n",
      "                   all        200        216      0.812      0.819      0.893      0.719\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/15         0G     0.6884     0.7723      1.163          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:113.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 34.8s2.6s\n",
      "                   all        200        216      0.909       0.75      0.896      0.727\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/15         0G     0.6652     0.7267      1.152          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:223.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 30.3s2.5s\n",
      "                   all        200        216      0.854      0.787      0.891      0.726\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/15         0G     0.6525     0.6825      1.145          5        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:143.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 31.0s2.5s\n",
      "                   all        200        216      0.863      0.801        0.9      0.736\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/15         0G     0.6747     0.6801      1.158          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:153.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 33.6s2.8s\n",
      "                   all        200        216      0.851      0.821      0.904       0.74\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/15         0G     0.6513     0.7052      1.143          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:183.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 32.1s2.7s\n",
      "                   all        200        216      0.846      0.815      0.906       0.74\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/15         0G     0.6525     0.6798      1.133          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:143.8ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 33.5s2.7s\n",
      "                   all        200        216      0.855      0.794      0.903      0.743\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/15         0G     0.6268     0.6525       1.12          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:213.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 32.9s2.9s\n",
      "                   all        200        216      0.781      0.861        0.9      0.743\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/15         0G     0.6314     0.6453      1.121          5        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:173.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 32.3s2.6s\n",
      "                   all        200        216      0.915      0.751      0.906      0.747\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/15         0G     0.6312     0.6556      1.103          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:143.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 29.4s2.5s\n",
      "                   all        200        216      0.898      0.773      0.907      0.746\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/15         0G     0.6205     0.6149      1.116          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:133.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 31.8s2.6s\n",
      "                   all        200        216      0.905      0.778      0.908      0.751\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/15         0G     0.6261     0.6086      1.118          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:073.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 33.1s2.7s\n",
      "                   all        200        216      0.801      0.847      0.905      0.754\n",
      "\n",
      "15 epochs completed in 1.716 hours.\n",
      "Optimizer stripped from /users/lanza/cvision/Polyps/runs/lr_finder/lr_test_01_1e-05/weights/last.pt, 52.0MB\n",
      "Optimizer stripped from /users/lanza/cvision/Polyps/runs/lr_finder/lr_test_01_1e-05/weights/best.pt, 52.0MB\n",
      "\n",
      "Validating /users/lanza/cvision/Polyps/runs/lr_finder/lr_test_01_1e-05/weights/best.pt...\n",
      "Ultralytics 8.3.217 🚀 Python-3.12.3 torch-2.9.0+cu128 CPU (Intel Xeon Gold 6252 CPU @ 2.10GHz)\n",
      "Model summary (fused): 92 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.5it/s 27.6s2.4s\n",
      "                   all        200        216      0.803      0.852      0.906      0.753\n",
      "Speed: 0.5ms preprocess, 124.4ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/users/lanza/cvision/Polyps/runs/lr_finder/lr_test_01_1e-05\u001b[0m\n",
      "Ultralytics 8.3.217 🚀 Python-3.12.3 torch-2.9.0+cu128 CPU (Intel Xeon Gold 6252 CPU @ 2.10GHz)\n",
      "Model summary (fused): 92 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 111.2±17.4 MB/s, size: 32.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /users/lanza/cvision/Polyps/kvasir_yolo_dataset/labels/val.cache... 200 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 200/200 236.6Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 25/25 0.7it/s 37.5s1.4ss\n",
      "                   all        200        216      0.853      0.833      0.884      0.765\n",
      "Speed: 0.4ms preprocess, 119.5ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/users/lanza/cvision/Polyps/runs/detect/val\u001b[0m\n",
      "  mAP@0.50: 0.8839 | Recall: 0.8333 | Score: 0.8688\n",
      "\n",
      "[2/6] → Testing lr0 = 0.0001 (run: lr_test_02_0.0001)...\n",
      "Ultralytics 8.3.217 🚀 Python-3.12.3 torch-2.9.0+cu128 CPU (Intel Xeon Gold 6252 CPU @ 2.10GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=kvasir_yolo_dataset/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.5, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.1, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=lr_test_02_0.0001, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=999, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/lr_finder, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/users/lanza/cvision/Polyps/runs/lr_finder/lr_test_02_0.0001, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=2, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
      "Model summary: 169 layers, 25,856,899 parameters, 25,856,883 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 96.2±23.0 MB/s, size: 29.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /users/lanza/cvision/Polyps/kvasir_yolo_dataset/labels/train.cache... 700 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 700/700 727.8Kit/s 0.0s\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 128.5±15.9 MB/s, size: 36.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /users/lanza/cvision/Polyps/kvasir_yolo_dataset/labels/val.cache... 200 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 200/200 295.6Kit/s 0.0s\n",
      "Plotting labels to /users/lanza/cvision/Polyps/runs/lr_finder/lr_test_02_0.0001/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0001, momentum=0.937) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/users/lanza/cvision/Polyps/runs/lr_finder/lr_test_02_0.0001\u001b[0m\n",
      "Starting training for 15 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/15         0G     0.9036      1.387      1.385          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:283.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 32.1s2.6s\n",
      "                   all        200        216        0.7      0.649      0.722      0.527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/15         0G     0.7859      1.006      1.251          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:233.8ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 29.9s2.5s\n",
      "                   all        200        216      0.754       0.75      0.815       0.63\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/15         0G     0.7439     0.8959      1.244          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:223.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 29.4s2.4s\n",
      "                   all        200        216      0.847      0.797      0.876      0.688\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/15         0G     0.7273     0.8459      1.241          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:293.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 30.0s2.4s\n",
      "                   all        200        216      0.867      0.815       0.89       0.69\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/15         0G     0.7106     0.7538      1.211          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:253.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 32.5s2.9s\n",
      "                   all        200        216      0.875       0.81      0.907      0.727\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/15         0G     0.6556     0.6834      1.154          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:063.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 31.1s2.6s\n",
      "                   all        200        216       0.84      0.849      0.904      0.691\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/15         0G     0.6653     0.6526      1.175          5        640: 100% ━━━━━━━━━━━━ 88/88 0.3it/s 5:503.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 30.9s2.4s\n",
      "                   all        200        216      0.836      0.829      0.904      0.716\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/15         0G     0.6296     0.6432      1.144          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 5:593.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 31.1s2.6s\n",
      "                   all        200        216      0.871      0.819      0.906      0.731\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/15         0G     0.6106     0.5933       1.13          4        640: 100% ━━━━━━━━━━━━ 88/88 0.3it/s 5:463.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 30.7s2.5s\n",
      "                   all        200        216      0.872      0.815      0.913      0.732\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/15         0G     0.6253      0.626      1.143          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 5:523.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.5it/s 28.2s2.3s\n",
      "                   all        200        216      0.862      0.841      0.923      0.742\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/15         0G     0.5969     0.5894      1.108          4        640: 100% ━━━━━━━━━━━━ 88/88 0.3it/s 5:453.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 33.1s2.8s\n",
      "                   all        200        216       0.88      0.838       0.91      0.721\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/15         0G     0.5986     0.5461      1.123          5        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 5:553.8ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 31.0s2.4s\n",
      "                   all        200        216      0.891      0.838       0.92      0.753\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/15         0G     0.5674     0.5138      1.096          4        640: 100% ━━━━━━━━━━━━ 88/88 0.3it/s 5:473.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.5it/s 27.9s2.3s\n",
      "                   all        200        216      0.939      0.819      0.935      0.779\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/15         0G     0.5766     0.5021      1.114          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 5:542.9ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 30.4s2.4s\n",
      "                   all        200        216      0.862      0.898      0.932      0.773\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/15         0G       0.55     0.4706      1.077          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 5:532.9ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 30.1s2.4s\n",
      "                   all        200        216      0.895      0.866      0.931      0.777\n",
      "\n",
      "15 epochs completed in 1.650 hours.\n",
      "Optimizer stripped from /users/lanza/cvision/Polyps/runs/lr_finder/lr_test_02_0.0001/weights/last.pt, 52.0MB\n",
      "Optimizer stripped from /users/lanza/cvision/Polyps/runs/lr_finder/lr_test_02_0.0001/weights/best.pt, 52.0MB\n",
      "\n",
      "Validating /users/lanza/cvision/Polyps/runs/lr_finder/lr_test_02_0.0001/weights/best.pt...\n",
      "Ultralytics 8.3.217 🚀 Python-3.12.3 torch-2.9.0+cu128 CPU (Intel Xeon Gold 6252 CPU @ 2.10GHz)\n",
      "Model summary (fused): 92 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.5it/s 27.0s2.2s\n",
      "                   all        200        216      0.939      0.819      0.935       0.78\n",
      "Speed: 0.6ms preprocess, 122.8ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/users/lanza/cvision/Polyps/runs/lr_finder/lr_test_02_0.0001\u001b[0m\n",
      "Ultralytics 8.3.217 🚀 Python-3.12.3 torch-2.9.0+cu128 CPU (Intel Xeon Gold 6252 CPU @ 2.10GHz)\n",
      "Model summary (fused): 92 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 173.3±35.5 MB/s, size: 34.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /users/lanza/cvision/Polyps/kvasir_yolo_dataset/labels/val.cache... 200 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 200/200 527.6Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 25/25 0.7it/s 34.1s1.3ss\n",
      "                   all        200        216      0.952      0.826      0.923      0.796\n",
      "Speed: 0.5ms preprocess, 115.9ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/users/lanza/cvision/Polyps/runs/detect/val2\u001b[0m\n",
      "  mAP@0.50: 0.9234 | Recall: 0.8262 | Score: 0.8942\n",
      "\n",
      "[3/6] → Testing lr0 = 0.001 (run: lr_test_03_0.001)...\n",
      "Ultralytics 8.3.217 🚀 Python-3.12.3 torch-2.9.0+cu128 CPU (Intel Xeon Gold 6252 CPU @ 2.10GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=kvasir_yolo_dataset/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.5, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.1, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=lr_test_03_0.001, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=999, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/lr_finder, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/users/lanza/cvision/Polyps/runs/lr_finder/lr_test_03_0.001, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=2, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
      "Model summary: 169 layers, 25,856,899 parameters, 25,856,883 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 129.0±23.0 MB/s, size: 29.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /users/lanza/cvision/Polyps/kvasir_yolo_dataset/labels/train.cache... 700 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 700/700 1.7Mit/s 0.0s0s\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 173.8±30.0 MB/s, size: 36.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /users/lanza/cvision/Polyps/kvasir_yolo_dataset/labels/val.cache... 200 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 200/200 559.6Kit/s 0.0s\n",
      "Plotting labels to /users/lanza/cvision/Polyps/runs/lr_finder/lr_test_03_0.001/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/users/lanza/cvision/Polyps/runs/lr_finder/lr_test_03_0.001\u001b[0m\n",
      "Starting training for 15 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/15         0G      1.125      1.653      1.579          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:133.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 29.4s2.4s\n",
      "                   all        200        216      0.327      0.648      0.513      0.276\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/15         0G      1.314       1.74      1.727          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:253.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 29.8s2.5s\n",
      "                   all        200        216      0.377      0.625      0.543      0.281\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/15         0G      1.289      1.578      1.719          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:123.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 29.0s2.3s\n",
      "                   all        200        216      0.563       0.56      0.599      0.372\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/15         0G       1.26      1.529      1.711          4        640: 100% ━━━━━━━━━━━━ 88/88 0.3it/s 5:493.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 29.6s2.5s\n",
      "                   all        200        216      0.597      0.644      0.638      0.382\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/15         0G       1.23      1.469      1.664          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 5:553.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 31.5s2.4s\n",
      "                   all        200        216      0.688      0.551      0.631      0.414\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/15         0G      1.176      1.508      1.598          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:022.9ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 30.5s2.4s\n",
      "                   all        200        216      0.682      0.676      0.738      0.512\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/15         0G      1.084      1.339      1.519          5        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:063.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.5it/s 28.3s2.4s\n",
      "                   all        200        216      0.643      0.643      0.697      0.462\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/15         0G      1.071      1.303      1.531          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 5:533.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 29.0s2.5s\n",
      "                   all        200        216      0.758      0.739      0.799      0.571\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/15         0G      1.031      1.195      1.496          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 5:592.9ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 32.8s2.5s\n",
      "                   all        200        216      0.699      0.721      0.783      0.535\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/15         0G      1.019      1.146      1.483          4        640: 100% ━━━━━━━━━━━━ 88/88 0.3it/s 5:512.9ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 32.8s2.8s\n",
      "                   all        200        216      0.806      0.752      0.833      0.599\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/15         0G     0.9657       1.14      1.413          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 5:593.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.5it/s 27.7s2.3s\n",
      "                   all        200        216      0.801      0.729      0.815      0.585\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/15         0G     0.9186      1.034      1.384          5        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:153.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 30.2s2.5s\n",
      "                   all        200        216      0.849      0.741      0.851      0.652\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/15         0G     0.9105      1.015       1.39          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:023.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 30.2s2.4s\n",
      "                   all        200        216       0.81      0.847      0.874      0.656\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/15         0G     0.8611     0.9335      1.334          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:113.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 31.0s2.4s\n",
      "                   all        200        216      0.855      0.816      0.902      0.682\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/15         0G     0.8187     0.8737      1.319          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 5:592.9ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 30.2s2.5s\n",
      "                   all        200        216      0.913      0.827      0.905        0.7\n",
      "\n",
      "15 epochs completed in 1.647 hours.\n",
      "Optimizer stripped from /users/lanza/cvision/Polyps/runs/lr_finder/lr_test_03_0.001/weights/last.pt, 52.0MB\n",
      "Optimizer stripped from /users/lanza/cvision/Polyps/runs/lr_finder/lr_test_03_0.001/weights/best.pt, 52.0MB\n",
      "\n",
      "Validating /users/lanza/cvision/Polyps/runs/lr_finder/lr_test_03_0.001/weights/best.pt...\n",
      "Ultralytics 8.3.217 🚀 Python-3.12.3 torch-2.9.0+cu128 CPU (Intel Xeon Gold 6252 CPU @ 2.10GHz)\n",
      "Model summary (fused): 92 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 29.8s2.4s\n",
      "                   all        200        216      0.913      0.828      0.905        0.7\n",
      "Speed: 0.5ms preprocess, 118.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/users/lanza/cvision/Polyps/runs/lr_finder/lr_test_03_0.001\u001b[0m\n",
      "Ultralytics 8.3.217 🚀 Python-3.12.3 torch-2.9.0+cu128 CPU (Intel Xeon Gold 6252 CPU @ 2.10GHz)\n",
      "Model summary (fused): 92 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 174.6±35.3 MB/s, size: 34.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /users/lanza/cvision/Polyps/kvasir_yolo_dataset/labels/val.cache... 200 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 200/200 214.4Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 25/25 0.5it/s 48.4s1.9ss\n",
      "                   all        200        216        0.9      0.834      0.902      0.731\n",
      "Speed: 0.4ms preprocess, 114.4ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/users/lanza/cvision/Polyps/runs/detect/val3\u001b[0m\n",
      "  mAP@0.50: 0.9017 | Recall: 0.8336 | Score: 0.8812\n",
      "\n",
      "[4/6] → Testing lr0 = 0.005 (run: lr_test_04_0.005)...\n",
      "Ultralytics 8.3.217 🚀 Python-3.12.3 torch-2.9.0+cu128 CPU (Intel Xeon Gold 6252 CPU @ 2.10GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=kvasir_yolo_dataset/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.5, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.005, lrf=0.1, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=lr_test_04_0.005, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=999, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/lr_finder, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/users/lanza/cvision/Polyps/runs/lr_finder/lr_test_04_0.005, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=2, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
      "Model summary: 169 layers, 25,856,899 parameters, 25,856,883 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 130.0±12.3 MB/s, size: 29.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /users/lanza/cvision/Polyps/kvasir_yolo_dataset/labels/train.cache... 700 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 700/700 1.4Mit/s 0.0s0s\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 187.5±29.1 MB/s, size: 36.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /users/lanza/cvision/Polyps/kvasir_yolo_dataset/labels/val.cache... 200 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 200/200 296.0Kit/s 0.0s\n",
      "Plotting labels to /users/lanza/cvision/Polyps/runs/lr_finder/lr_test_04_0.005/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.005, momentum=0.937) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/users/lanza/cvision/Polyps/runs/lr_finder/lr_test_04_0.005\u001b[0m\n",
      "Starting training for 15 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/15         0G      1.861      2.671      2.257          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:383.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.3it/s 40.0s3.3s\n",
      "                   all        200        216    0.00376      0.676     0.0035    0.00108\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/15         0G      1.921       2.51      2.331          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:293.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 36.0s2.9s\n",
      "                   all        200        216    0.00831     0.0463    0.00446    0.00104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/15         0G      1.801      2.225      2.211          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:363.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 36.4s3.1s\n",
      "                   all        200        216     0.0638       0.56      0.165     0.0753\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/15         0G      1.696       2.07       2.11          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 7:003.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 36.0s3.1s\n",
      "                   all        200        216     0.0638      0.579     0.0531     0.0255\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/15         0G      1.569       2.01      2.027          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:533.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 34.2s3.1s\n",
      "                   all        200        216      0.435       0.51      0.469      0.261\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/15         0G      1.463      1.856      1.889          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:433.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 33.0s2.8s\n",
      "                   all        200        216      0.683      0.449      0.512      0.308\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/15         0G      1.439      1.728      1.837          5        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:343.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 34.1s2.9s\n",
      "                   all        200        216      0.582      0.592        0.6      0.374\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/15         0G      1.388      1.727      1.817          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:283.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 33.3s2.7s\n",
      "                   all        200        216      0.538      0.639      0.604      0.373\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/15         0G      1.367      1.728      1.789          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:283.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 33.6s2.7s\n",
      "                   all        200        216      0.611      0.611      0.587      0.357\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/15         0G      1.323      1.653      1.753          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:423.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 34.7s2.8s\n",
      "                   all        200        216      0.533       0.63      0.591      0.379\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/15         0G      1.264      1.611      1.689          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:343.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 32.7s2.8s\n",
      "                   all        200        216      0.702      0.648       0.68      0.448\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/15         0G      1.229      1.538      1.653          5        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:293.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 33.7s2.8s\n",
      "                   all        200        216      0.611      0.604      0.627      0.396\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/15         0G       1.27       1.56      1.702          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:274.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 34.2s2.9s\n",
      "                   all        200        216      0.651      0.676      0.669      0.445\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/15         0G      1.183      1.468      1.613          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:343.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 34.1s2.9s\n",
      "                   all        200        216      0.659      0.663      0.718      0.488\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/15         0G      1.111      1.359      1.558          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:363.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 32.5s2.8s\n",
      "                   all        200        216      0.764      0.661      0.753      0.518\n",
      "\n",
      "15 epochs completed in 1.804 hours.\n",
      "Optimizer stripped from /users/lanza/cvision/Polyps/runs/lr_finder/lr_test_04_0.005/weights/last.pt, 52.0MB\n",
      "Optimizer stripped from /users/lanza/cvision/Polyps/runs/lr_finder/lr_test_04_0.005/weights/best.pt, 52.0MB\n",
      "\n",
      "Validating /users/lanza/cvision/Polyps/runs/lr_finder/lr_test_04_0.005/weights/best.pt...\n",
      "Ultralytics 8.3.217 🚀 Python-3.12.3 torch-2.9.0+cu128 CPU (Intel Xeon Gold 6252 CPU @ 2.10GHz)\n",
      "Model summary (fused): 92 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 33.3s2.8s\n",
      "                   all        200        216      0.763      0.662      0.753      0.519\n",
      "Speed: 0.6ms preprocess, 139.1ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/users/lanza/cvision/Polyps/runs/lr_finder/lr_test_04_0.005\u001b[0m\n",
      "Ultralytics 8.3.217 🚀 Python-3.12.3 torch-2.9.0+cu128 CPU (Intel Xeon Gold 6252 CPU @ 2.10GHz)\n",
      "Model summary (fused): 92 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 173.6±25.4 MB/s, size: 34.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /users/lanza/cvision/Polyps/kvasir_yolo_dataset/labels/val.cache... 200 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 200/200 213.9Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 25/25 0.7it/s 33.9s1.2ss\n",
      "                   all        200        216      0.744      0.671      0.739      0.557\n",
      "Speed: 0.4ms preprocess, 113.2ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/users/lanza/cvision/Polyps/runs/detect/val4\u001b[0m\n",
      "  mAP@0.50: 0.7391 | Recall: 0.6713 | Score: 0.7188\n",
      "\n",
      "[5/6] → Testing lr0 = 0.01 (run: lr_test_05_0.01)...\n",
      "Ultralytics 8.3.217 🚀 Python-3.12.3 torch-2.9.0+cu128 CPU (Intel Xeon Gold 6252 CPU @ 2.10GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=kvasir_yolo_dataset/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.5, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.1, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=lr_test_05_0.01, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=999, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/lr_finder, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/users/lanza/cvision/Polyps/runs/lr_finder/lr_test_05_0.01, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=2, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
      "Model summary: 169 layers, 25,856,899 parameters, 25,856,883 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 142.2±24.1 MB/s, size: 29.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /users/lanza/cvision/Polyps/kvasir_yolo_dataset/labels/train.cache... 700 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 700/700 727.8Kit/s 0.0s\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 195.8±39.9 MB/s, size: 36.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /users/lanza/cvision/Polyps/kvasir_yolo_dataset/labels/val.cache... 200 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 200/200 285.1Kit/s 0.0s\n",
      "Plotting labels to /users/lanza/cvision/Polyps/runs/lr_finder/lr_test_05_0.01/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/users/lanza/cvision/Polyps/runs/lr_finder/lr_test_05_0.01\u001b[0m\n",
      "Starting training for 15 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/15         0G      2.347      3.432      2.771          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:063.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 33.1s2.8s\n",
      "                   all        200        216          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/15         0G      2.476      3.433      3.028          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:083.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 33.6s3.0s\n",
      "                   all        200        216          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/15         0G      2.348      3.347      2.978          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:293.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 33.3s2.7s\n",
      "                   all        200        216    0.00334      0.231    0.00191   0.000603\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/15         0G      2.292      3.075      2.897          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:123.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 34.8s2.8s\n",
      "                   all        200        216     0.0292     0.0185    0.00347    0.00136\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/15         0G       2.17      2.935      2.765          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:123.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 34.0s2.9s\n",
      "                   all        200        216      0.221      0.278      0.146     0.0537\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/15         0G      2.085      2.744      2.644          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:033.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 34.0s2.9s\n",
      "                   all        200        216      0.186      0.269       0.13     0.0528\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/15         0G       2.03      2.574      2.574          5        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:083.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 32.0s2.7s\n",
      "                   all        200        216      0.327      0.324      0.222     0.0954\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/15         0G      1.964      2.402      2.523          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:103.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 31.5s2.6s\n",
      "                   all        200        216      0.337      0.356      0.254     0.0969\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/15         0G       1.92      2.341      2.446          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:093.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 31.5s2.6s\n",
      "                   all        200        216      0.308      0.319      0.268      0.125\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/15         0G      1.842      2.237      2.387          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:163.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 30.2s2.6s\n",
      "                   all        200        216      0.349      0.296      0.297      0.127\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/15         0G      1.851      2.202      2.398          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:103.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 31.6s2.6s\n",
      "                   all        200        216      0.365      0.356        0.3      0.147\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/15         0G       1.76      2.085      2.293          5        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:183.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 30.8s2.6s\n",
      "                   all        200        216      0.439      0.449      0.411        0.2\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/15         0G      1.765      2.064      2.277          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:093.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 32.1s2.7s\n",
      "                   all        200        216      0.354      0.407      0.341      0.181\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/15         0G      1.657      2.012      2.172          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:153.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 30.3s2.5s\n",
      "                   all        200        216      0.484      0.468      0.446      0.213\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/15         0G      1.648      1.994      2.165          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:204.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 31.9s2.6s\n",
      "                   all        200        216      0.381      0.468      0.382      0.209\n",
      "\n",
      "15 epochs completed in 1.693 hours.\n",
      "Optimizer stripped from /users/lanza/cvision/Polyps/runs/lr_finder/lr_test_05_0.01/weights/last.pt, 52.0MB\n",
      "Optimizer stripped from /users/lanza/cvision/Polyps/runs/lr_finder/lr_test_05_0.01/weights/best.pt, 52.0MB\n",
      "\n",
      "Validating /users/lanza/cvision/Polyps/runs/lr_finder/lr_test_05_0.01/weights/best.pt...\n",
      "Ultralytics 8.3.217 🚀 Python-3.12.3 torch-2.9.0+cu128 CPU (Intel Xeon Gold 6252 CPU @ 2.10GHz)\n",
      "Model summary (fused): 92 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.5it/s 28.2s2.4s\n",
      "                   all        200        216      0.484      0.468      0.447      0.213\n",
      "Speed: 0.5ms preprocess, 125.4ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/users/lanza/cvision/Polyps/runs/lr_finder/lr_test_05_0.01\u001b[0m\n",
      "Ultralytics 8.3.217 🚀 Python-3.12.3 torch-2.9.0+cu128 CPU (Intel Xeon Gold 6252 CPU @ 2.10GHz)\n",
      "Model summary (fused): 92 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 119.6±40.6 MB/s, size: 34.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /users/lanza/cvision/Polyps/kvasir_yolo_dataset/labels/val.cache... 200 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 200/200 212.9Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 25/25 0.6it/s 40.0s2.0ss\n",
      "                   all        200        216      0.707      0.403      0.546      0.278\n",
      "Speed: 0.4ms preprocess, 112.0ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1m/users/lanza/cvision/Polyps/runs/detect/val5\u001b[0m\n",
      "  mAP@0.50: 0.5464 | Recall: 0.4028 | Score: 0.5033\n",
      "\n",
      "[6/6] → Testing lr0 = 0.05 (run: lr_test_06_0.05)...\n",
      "Ultralytics 8.3.217 🚀 Python-3.12.3 torch-2.9.0+cu128 CPU (Intel Xeon Gold 6252 CPU @ 2.10GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=kvasir_yolo_dataset/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.5, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.05, lrf=0.1, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=lr_test_06_0.05, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=999, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/lr_finder, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/users/lanza/cvision/Polyps/runs/lr_finder/lr_test_06_0.05, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=2, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
      "Model summary: 169 layers, 25,856,899 parameters, 25,856,883 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 129.0±15.7 MB/s, size: 29.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /users/lanza/cvision/Polyps/kvasir_yolo_dataset/labels/train.cache... 700 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 700/700 1.3Mit/s 0.0s0s\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 185.3±35.6 MB/s, size: 36.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /users/lanza/cvision/Polyps/kvasir_yolo_dataset/labels/val.cache... 200 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 200/200 521.4Kit/s 0.0s\n",
      "Plotting labels to /users/lanza/cvision/Polyps/runs/lr_finder/lr_test_06_0.05/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.05, momentum=0.937) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/users/lanza/cvision/Polyps/runs/lr_finder/lr_test_06_0.05\u001b[0m\n",
      "Starting training for 15 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/15         0G      2.723      4.033      3.097          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:413.9ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.3it/s 40.5s3.0s\n",
      "                   all        200        216    0.00595      0.444    0.00475    0.00149\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/15         0G      2.671       3.57       3.19          4        640: 100% ━━━━━━━━━━━━ 88/88 0.2it/s 6:443.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 0.4it/s 36.1s3.2s\n",
      "                   all        200        216          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/15         0G      2.547       3.56      3.269          9        640: 52% ━━━━━━────── 46/88 0.2it/s 3:39<3:216"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ========== STEP 2: Find Best Learning Rate ==========\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STEP 2: FINDING BEST LEARNING RATE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    best_lr0 = auto_find_best_lr(\n",
    "        data_yaml_path=DATA_YAML,\n",
    "        model_size=MODEL_SIZE,\n",
    "        img_size=640,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        test_lr0_values=[1e-5, 1e-4, 1e-3, 5e-3, 1e-2, 5e-2],\n",
    "        epochs=15\n",
    "    )\n",
    "    print(\"Best lr0 found:\", best_lr0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb5803d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 3: TRAINING MODEL\n",
      "======================================================================\n",
      "Using lr0 = 0.0001\n",
      "\n",
      "Using CPU\n",
      "New https://pypi.org/project/ultralytics/8.3.218 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.217 🚀 Python-3.12.3 torch-2.9.0+cu128 CPU (Intel Xeon Gold 6252 CPU @ 2.10GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=kvasir_yolo_dataset/data.yaml, degrees=10.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.0, exist_ok=False, fliplr=0.5, flipud=0.5, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.4, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.1, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=polyp_detection2, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/users/lanza/cvision/Polyps/runs/detect/polyp_detection2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.2, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
      "Model summary: 169 layers, 25,856,899 parameters, 25,856,883 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 61.4±30.4 MB/s, size: 28.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /users/lanza/cvision/Polyps/kvasir_yolo_dataset/labels/train.cache... 700 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 700/700 895.1Kit/s 0.0s\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 117.9±37.7 MB/s, size: 37.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /users/lanza/cvision/Polyps/kvasir_yolo_dataset/labels/val.cache... 200 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 200/200 317.6Kit/s 0.0s\n",
      "Plotting labels to /users/lanza/cvision/Polyps/runs/detect/polyp_detection2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0001, momentum=0.937) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/users/lanza/cvision/Polyps/runs/detect/polyp_detection2\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/30         0G      1.286      2.193      1.774          9        640: 12% ━─────────── 11/88 0.2it/s 1:16<5:45"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    " # ========== STEP 3: Train Model ==========\n",
    "    best_lr0 = 1e-4 # default in case STEP 2 is skipped\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STEP 3: TRAINING MODEL\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Using lr0 = {best_lr0}\\n\")\n",
    "    \n",
    "    model = train_yolo(\n",
    "        data_yaml_path=DATA_YAML,\n",
    "        model_size=MODEL_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        img_size=640, #try to set 800\n",
    "        batch_size=BATCH_SIZE,\n",
    "        lr0=1e-4 \n",
    "    )\n",
    "\n",
    "    # Find best model\n",
    "    BEST_MODEL_PATH = \"runs/detect/polyp_detection/weights/best.pt\"\n",
    "    if not os.path.isfile(BEST_MODEL_PATH):\n",
    "        candidates = sorted(glob.glob(\"runs/detect/*/weights/best.pt\"))\n",
    "        if candidates:\n",
    "            BEST_MODEL_PATH = candidates[-1]\n",
    "            print(f\"\\n[INFO] Using model: {BEST_MODEL_PATH}\")\n",
    "        else:\n",
    "            print(\"\\n[ERROR] Could not find best.pt\")\n",
    "            sys.exit(1)\n",
    "            \n",
    "\n",
    "    # ========== STEP 5: Test on Sample Image ==========\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STEP 5: TESTING ON SAMPLE IMAGE\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # Check for test images first, fallback to val if needed\n",
    "    test_images = glob.glob(f\"{OUTPUT_DIR}/images/test/*.*\")\n",
    "    val_images = glob.glob(f\"{OUTPUT_DIR}/images/val/*.*\")\n",
    "\n",
    "    if test_images:\n",
    "        TEST_IMAGE = random.choice(test_images)\n",
    "        print(f\"\\n✓ Found {len(test_images)} test images\")\n",
    "        print(f\"Visualizing: {TEST_IMAGE}\")\n",
    "        predict_and_visualize(BEST_MODEL_PATH, TEST_IMAGE, conf_threshold=0.5)\n",
    "    elif val_images:\n",
    "        TEST_IMAGE = random.choice(val_images)\n",
    "        print(f\"\\n[WARN] No test images found. Using validation set instead.\")\n",
    "        print(f\"✓ Found {len(val_images)} val images\")\n",
    "        print(f\"Visualizing: {TEST_IMAGE}\")\n",
    "        predict_and_visualize(BEST_MODEL_PATH, TEST_IMAGE, conf_threshold=0.5)\n",
    "    else:\n",
    "        print(\"[ERROR] No images found in test or val sets for visualization\")\n",
    "\n",
    "    # ========== STEP 5b: Run on ALL Test Images ==========\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STEP 5b: RUNNING INFERENCE ON ALL TEST IMAGES\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    if test_images:\n",
    "        predict_on_all_images(BEST_MODEL_PATH, f\"{OUTPUT_DIR}/images/test\", data_yaml_path=DATA_YAML, conf_threshold=0.5, save_dir='test_predictions')\n",
    "    elif val_images:\n",
    "        print(\"[WARN] No test images found. Running on validation set instead...\")\n",
    "        predict_on_all_images(BEST_MODEL_PATH, f\"{OUTPUT_DIR}/images/val\", data_yaml_path=DATA_YAML, conf_threshold=0.5, save_dir='val_predictions')\n",
    "    else:\n",
    "        print(\"[ERROR] No images found in test or val sets for batch inference\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9a848f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 4: MODEL EVALUATION\n",
      "======================================================================\n",
      "Ultralytics 8.3.217 🚀 Python-3.12.3 torch-2.9.0+cu128 CPU (Intel Xeon Gold 6252 CPU @ 2.10GHz)\n",
      "Model summary (fused): 92 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 165.9±43.5 MB/s, size: 56.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /users/lanza/cvision/Polyps/kvasir_yolo_dataset/labels/test... 100 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 100/100 815.4it/s 0.1s1s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /users/lanza/cvision/Polyps/kvasir_yolo_dataset/labels/test.cache\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 0.4it/s 20.0s3.7ss\n",
      "                   all        100        105      0.941      0.905      0.932      0.757\n",
      "Speed: 1.4ms preprocess, 193.0ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/users/lanza/cvision/Polyps/runs/detect/val7\u001b[0m\n",
      "\n",
      "======================================================================\n",
      "EVALUATION RESULTS ON TEST SET\n",
      "======================================================================\n",
      "mAP@0.50     : 0.9321\n",
      "mAP@0.50:0.95: 0.7566\n",
      "Precision    : 0.9406\n",
      "Recall       : 0.9048\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "BEST_MODEL_PATH = \"runs/detect/polyp_detection2/weights/best.pt\"\n",
    "# ========== STEP 4: Evaluate Model ==========\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 4: MODEL EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    metrics = evaluate_model(BEST_MODEL_PATH, DATA_YAML, split='test')\n",
    "except Exception as e:\n",
    "    print(f\"\\n[WARN] Test split unavailable ({e}), using validation set\")\n",
    "    metrics = evaluate_model(BEST_MODEL_PATH, DATA_YAML, split='val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86eca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # ========== STEP 6: Export Model ==========\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STEP 6: EXPORTING MODEL\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    export_model(BEST_MODEL_PATH, format='onnx')\n",
    "    export_model(BEST_MODEL_PATH, format='tensorrt')\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"ALL STEPS COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12d4cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 5b: RUNNING INFERENCE ON ALL TEST IMAGES\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RUNNING INFERENCE ON ALL 100 TEST IMAGES\n",
      "======================================================================\n",
      "\n",
      "✓ cju2hgsptlfam0835o3b59h1o.jpg: 1 polyp(s)\n",
      "✓ cju13hp5rnbjx0835bf0jowgx.jpg: 1 polyp(s)\n",
      "✓ cju7er4kc2opa0801anuxc0eb.jpg: 1 polyp(s)\n",
      "✓ cju8czvnztbf40871b4m7t78w.jpg: 1 polyp(s)\n",
      "✓ cju890guyoiti098753yg6cdu.jpg: 1 polyp(s)\n",
      "✓ cju2z45kuzf6d0988nz2c819m.jpg: 1 polyp(s)\n",
      "✓ cju2qz06823a40878ojcz9ccx.jpg: 1 polyp(s)\n",
      "✓ cju5ew4h9cqaf0818rrczkmqh.jpg: 1 polyp(s)\n",
      "✓ cju87mrypnb1e0818scv1mxxg.jpg: 1 polyp(s)\n",
      "✓ cju1h5w4wxajx0835mc954kxy.jpg: 1 polyp(s)\n",
      "✓ cju0s690hkp960855tjuaqvv0.jpg: 1 polyp(s)\n",
      "✓ cju6vucxvvlda0755j7msqnya.jpg: 1 polyp(s)\n",
      "✓ cju15ptjtppz40988odsm9azx.jpg: 1 polyp(s)\n",
      "✓ cju7d4jk723eu0817bqz2n39m.jpg: 1 polyp(s)\n",
      "✓ cju5i39mreass0817au8p22zy.jpg: 1 polyp(s)\n",
      "✓ cju76l27oyrw907551ri2a7fl.jpg: 1 polyp(s)\n",
      "✓ cju8b5p40r2c60987ofa0mu03.jpg: 1 polyp(s)\n",
      "✓ cju5c5xc7algd0817pb1ej5yo.jpg: 1 polyp(s)\n",
      "✓ cju34m7h536wq0988xz7gx79v.jpg: 1 polyp(s)\n",
      "✓ cju7d7aut2a2p0818z4uxc6cd.jpg: 1 polyp(s)\n",
      "✓ cju2rnkt22xep0801as160g9t.jpg: 2 polyp(s)\n",
      "✓ cju8a56vxpy780850r45yu4wk.jpg: 1 polyp(s)\n",
      "✓ cju6z2616wqbk07555bvnuyr1.jpg: 1 polyp(s)\n",
      "  cju34uhepd3dd0799hs8782ad.jpg: No polyps detected\n",
      "✓ cju7epwj82koz098713apjnzo.jpg: 1 polyp(s)\n",
      "✓ ck2395w2mb4vu07480otsu6tw.jpg: 1 polyp(s)\n",
      "✓ cju6x97w4vwua0850x0997r0a.jpg: 1 polyp(s)\n",
      "✓ cju7dizi82h2i0755doucgnt3.jpg: 1 polyp(s)\n",
      "✓ cju5x28nzm7t907558ocq4bt7.jpg: 1 polyp(s)\n",
      "✓ cju5y7buemcw80987p0r30g9f.jpg: 1 polyp(s)\n",
      "✓ cju5uhrdwkmsu0817ervv91l8.jpg: 1 polyp(s)\n",
      "✓ cju1fm3id6gl50801r3fok20c.jpg: 1 polyp(s)\n",
      "✓ cju2y26c588bo07993ksd8eoz.jpg: 1 polyp(s)\n",
      "✓ cju7ekbo32pft0871fv7kzwb9.jpg: 1 polyp(s)\n",
      "✓ cju42g865lorv07552ytz6xxa.jpg: 1 polyp(s)\n",
      "✓ cju6uzxk0v83p0801rcwnexdu.jpg: 1 polyp(s)\n",
      "✓ cju42xpi8lw4w0871ve317a1p.jpg: 1 polyp(s)\n",
      "✓ cju2nd7l7z98o0799gfjvyfmw.jpg: 1 polyp(s)\n",
      "✓ cju84gpefknwm098714oq8q61.jpg: 1 polyp(s)\n",
      "✓ cjyzjzssvd8pq0838f4nolj5l.jpg: 1 polyp(s)\n",
      "✓ cju84hibuktj80871u519o71q.jpg: 1 polyp(s)\n",
      "✓ cju6z600qwh4z081700qimgl9.jpg: 1 polyp(s)\n",
      "✓ cju2hewssldzx0835ep795xu0.jpg: 1 polyp(s)\n",
      "✓ cju1bm8063nmh07996rsjjemq.jpg: 1 polyp(s)\n",
      "✓ cju1hp9i2xu8e0988u2dazk7m.jpg: 1 polyp(s)\n",
      "✓ cju77idwfz36d0871tzfzz51i.jpg: 1 polyp(s)\n",
      "✓ cju8a1jtvpt9m081712iwkca7.jpg: 1 polyp(s)\n",
      "✓ cju7awzmu1ncs0871hziy65zx.jpg: 1 polyp(s)\n",
      "✓ cju3xzvnzj0hd0755xprz39nj.jpg: 1 polyp(s)\n",
      "✓ cju2xbk0080y80801eghyddi2.jpg: 1 polyp(s)\n",
      "✓ ck2da7fwcjfis07218r1rvm95.jpg: 1 polyp(s)\n",
      "✓ cju17r8il13910799dr2wme2e.jpg: 1 polyp(s)\n",
      "✓ cju2rz4k434s70855wwx3ddtx.jpg: 1 polyp(s)\n",
      "✓ cju5waeduln160817w0agirve.jpg: 1 polyp(s)\n",
      "✓ cju85plp7lmkw0850rx42jdpf.jpg: 1 polyp(s)\n",
      "✓ cju3y54kwj3nr0801biidlb4e.jpg: 1 polyp(s)\n",
      "✓ cju6us80mv1b50871ebyq2wxa.jpg: 1 polyp(s)\n",
      "✓ cju88rl5eo94l0850kf5wtrm1.jpg: 1 polyp(s)\n",
      "✓ cju5g163vd6mt0817uccuga6u.jpg: 1 polyp(s)\n",
      "✓ cju43in5fm22c08175rxziqrk.jpg: 1 polyp(s)\n",
      "✓ cju5wqonpm0e60801z88ewmy1.jpg: 1 polyp(s)\n",
      "✓ cju45ty6zn9oz0850qy4qnck1.jpg: 1 polyp(s)\n",
      "✓ cju2phaksnahz0993yxogjcpv.jpg: 1 polyp(s)\n",
      "✓ cju2hos57llxm08359g92p6jj.jpg: 1 polyp(s)\n",
      "✓ cju84jdl9kv0i0871eog9b3i9.jpg: 1 polyp(s)\n",
      "✓ cju77vvcwzcm50850lzoykuva.jpg: 1 polyp(s)\n",
      "✓ cju8ayeq7r1fb0818z1junacy.jpg: 1 polyp(s)\n",
      "✓ cju1cbokpuiw70988j4lq1fpi.jpg: 2 polyp(s)\n",
      "✓ ck2bxqz3evvg20794iiyv5v2m.jpg: 1 polyp(s)\n",
      "✓ cju2igw4gvxds0878808qj398.jpg: 1 polyp(s)\n",
      "✓ cju2qu37qobl50993aw7ghcfq.jpg: 1 polyp(s)\n",
      "✓ cju2yv4imv6cz099314jveiib.jpg: 1 polyp(s)\n",
      "✓ cju5udcufki0s09874ll1dbr5.jpg: 1 polyp(s)\n",
      "✓ cju2zblxw9848087853csbrx1.jpg: 1 polyp(s)\n",
      "  cju35740hzm0g0993zl5ic246.jpg: No polyps detected\n",
      "✓ cju88fpm4o0tl0871w1i6a4ds.jpg: 1 polyp(s)\n",
      "✓ cju7ap09p1kz10850ldccjebj.jpg: 1 polyp(s)\n",
      "✓ cju87tyddnnad0755bj0wxahe.jpg: 1 polyp(s)\n",
      "✓ cju2hx006vidl0799igm81vmh.jpg: 1 polyp(s)\n",
      "✓ cju772304yw5t0818vbw8kkjf.jpg: 1 polyp(s)\n",
      "✓ cju2zgbj9zmrw0835nnlzxj4c.jpg: 1 polyp(s)\n",
      "✓ cju1c4fcu40hl07992b8gj0c8.jpg: 1 polyp(s)\n",
      "✓ cju32csyfblyh080170aa3x5p.jpg: 1 polyp(s)\n",
      "✓ cju334jzo261t0835yqudnfs1.jpg: 1 polyp(s)\n",
      "✓ cju5ht88gedbu0755xrcuddcx.jpg: 1 polyp(s)\n",
      "✓ cju5wi6bqlxy90755bu227nvb.jpg: 1 polyp(s)\n",
      "✓ cju2tvrvm53ws0801a0jfjdxg.jpg: 2 polyp(s)\n",
      "✓ cju8cdeazsm8h0801jxifmzur.jpg: 1 polyp(s)\n",
      "✓ cju1f5x1164xv08555654c24r.jpg: 1 polyp(s)\n",
      "✓ cju3518w2d838079939fqztbc.jpg: 1 polyp(s)\n",
      "✓ cju5uxjnol2r509871qv2yeia.jpg: 2 polyp(s)\n",
      "✓ cju32jcdabepz0878d0cznmfe.jpg: 1 polyp(s)\n",
      "✓ cju5c7oijaqmq09878qwgqv8n.jpg: 1 polyp(s)\n",
      "✓ cju5u4pywk81x0817vn9pe14z.jpg: 1 polyp(s)\n",
      "✓ cju7ae7bq1f820987toc8si1d.jpg: 1 polyp(s)\n",
      "✓ cju7dz5yy2i7z0801ausi7rna.jpg: 1 polyp(s)\n",
      "✓ cju13fwthn9mq0835gacxgy01.jpg: 1 polyp(s)\n",
      "✓ cju7cufm7298k0755j09uf3of.jpg: 1 polyp(s)\n",
      "✓ cju5eq8c8ck690850vix98hv3.jpg: 1 polyp(s)\n",
      "  cju2xlcqxy9c60988vjacdznb.jpg: No polyps detected\n",
      "\n",
      "======================================================================\n",
      "INFERENCE SUMMARY\n",
      "======================================================================\n",
      "Total images:           100\n",
      "Images with polyps:     97\n",
      "Images without polyps:  3\n",
      "Total polyps detected:  101\n",
      "Predictions saved to:   /users/lanza/cvision/Polyps/test_predictions\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "BEST_MODEL_PATH = \"runs/detect/polyp_detection2/weights/best.pt\"\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 5: TESTING ON SAMPLE IMAGE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check for test images first, fallback to val if needed\n",
    "test_images = glob.glob(f\"{OUTPUT_DIR}/images/test/*.*\")\n",
    "val_images = glob.glob(f\"{OUTPUT_DIR}/images/val/*.*\")\n",
    "\n",
    "if test_images:\n",
    "    TEST_IMAGE = random.choice(test_images)\n",
    "    print(f\"\\n✓ Found {len(test_images)} test images\")\n",
    "    print(f\"Visualizing: {TEST_IMAGE}\")\n",
    "    predict_and_visualize(BEST_MODEL_PATH, TEST_IMAGE, conf_threshold=0.5)\n",
    "elif val_images:\n",
    "    TEST_IMAGE = random.choice(val_images)\n",
    "    print(f\"\\n[WARN] No test images found. Using validation set instead.\")\n",
    "    print(f\"✓ Found {len(val_images)} val images\")\n",
    "    print(f\"Visualizing: {TEST_IMAGE}\")\n",
    "    predict_and_visualize(BEST_MODEL_PATH, TEST_IMAGE, conf_threshold=0.5)\n",
    "else:\n",
    "    print(\"[ERROR] No images found in test or val sets for visualization\")\n",
    "\n",
    "# ========== STEP 5b: Run on ALL Test Images ==========\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 5b: RUNNING INFERENCE ON ALL TEST IMAGES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if test_images:\n",
    "    predict_on_all_images(BEST_MODEL_PATH, f\"{OUTPUT_DIR}/images/test\", data_yaml_path=DATA_YAML, conf_threshold=0.5, save_dir='test_predictions')\n",
    "elif val_images:\n",
    "    print(\"[WARN] No test images found. Running on validation set instead...\")\n",
    "    predict_on_all_images(BEST_MODEL_PATH, f\"{OUTPUT_DIR}/images/val\", data_yaml_path=DATA_YAML, conf_threshold=0.5, save_dir='val_predictions')\n",
    "else:\n",
    "    print(\"[ERROR] No images found in test or val sets for batch inference\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
