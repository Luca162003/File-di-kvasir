{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7430c4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import yaml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a815fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/luca/Desktop/Pitone/File-di-kvasir/Kvasir-mask\n"
     ]
    }
   ],
   "source": [
    "print(\"Current working directory:\", os.getcwd())\n",
    "os.chdir(\"/home/luca/Desktop/Luca/File-di-kvasir_Daniele/\") #metti come directory il path del progetto, all'interno del quale si trova la cartella kvasir-mask\n",
    "\n",
    "# ========== CONFIGURATION ==========\n",
    "IMAGE_DIR = \"Kvasir-mask/images\"          \n",
    "MASK_DIR = \"Kvasir-mask/masks\"            \n",
    "JSON_PATH = \"Kvasir-mask/bounding-boxes.json\" \n",
    "OUTPUT_DIR = \"Kvasir-mask/kvasir_yolo_seg_dataset\"\n",
    "MODEL_SIZE = 'm'  \n",
    "BATCH_SIZE = 16   \n",
    "EPOCHS = 100\n",
    "IMG_SIZE = 640\n",
    "DATA_YAML = f\"{OUTPUT_DIR}/data.yaml\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1f5ea1",
   "metadata": {},
   "source": [
    "PART 1: DATASET CONVERTER (SEGMENTATION WITH NEGATIVE SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08ef6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KvasirToYOLOSeg:\n",
    "    \"\"\"Convert Kvasir masks + JSON to YOLO segmentation format with healthy images.\"\"\"\n",
    "    MIN_AREA = 200  # Minimum area to consider a contour a valid polyp\n",
    "    MAX_ASPECT_RATIO = 8.0\n",
    "\n",
    "    def __init__(self, image_dir, mask_dir, json_path, output_dir, seed=42):\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.mask_dir = Path(mask_dir)\n",
    "        self.json_path = Path(json_path)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.seed = seed\n",
    "\n",
    "        # Load JSON annotations (for polyp images only)\n",
    "        with open(self.json_path, 'r') as f:\n",
    "            self.annotations = json.load(f)\n",
    "\n",
    "        if not isinstance(self.annotations, dict):\n",
    "            raise ValueError(\"Annotations JSON must be a dict keyed by image ID.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def mask_to_polygon(mask):\n",
    "        \n",
    "\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        if not contours:\n",
    "            return None\n",
    "        \n",
    "        valid_polygons = []\n",
    "        \n",
    "        # Calculate the approximation tolerance (epsilon) based on the perimeter\n",
    "        epsilon_multiplier = 0.001\n",
    "\n",
    "        for contour in contours:\n",
    "            perimeter = cv2.arcLength(contour, True)\n",
    "            epsilon = epsilon_multiplier * perimeter\n",
    "            \n",
    "            # Approximate the contour to simplify the polygon\n",
    "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "            \n",
    "            # Calculate metrics for noise filtering\n",
    "            area = cv2.contourArea(approx)\n",
    "            x, y, approx_w, approx_h = cv2.boundingRect(approx)\n",
    "            \n",
    "            # Avoid division by zero\n",
    "            aspect_ratio = approx_w / approx_h if approx_h != 0 else KvasirToYOLOSeg.MAX_ASPECT_RATIO + 1\n",
    "            \n",
    "            # 1. Area Check: Filters out contours that are too small (noise)\n",
    "            if area < KvasirToYOLOSeg.MIN_AREA:\n",
    "                continue\n",
    "            \n",
    "            # 2. Filter out contours that are too thin/elongated (e.g., line artifacts)\n",
    "            if aspect_ratio > KvasirToYOLOSeg.MAX_ASPECT_RATIO or 1/aspect_ratio > KvasirToYOLOSeg.MAX_ASPECT_RATIO:\n",
    "                continue\n",
    "            \n",
    "            # Append the raw NumPy array coordinates\n",
    "            valid_polygons.append(approx.reshape(-1, 2))\n",
    "            \n",
    "        return valid_polygons if valid_polygons else None\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize_polygon(polygon, img_width, img_height):\n",
    "        \"\"\"Normalize polygon coordinates to [0, 1].\"\"\"\n",
    "        polygon = polygon.astype(float)\n",
    "        polygon[:, 0] /= img_width\n",
    "        polygon[:, 1] /= img_height\n",
    "        \n",
    "        # Clamp to valid range\n",
    "        polygon = np.clip(polygon, 0.0, 1.0)\n",
    "        return polygon\n",
    "\n",
    "    def prepare_dataset(self, train_split=0.7, val_split=0.2, test_split=0.1):\n",
    "        \"\"\"Prepare segmentation dataset with polyp + healthy images.\"\"\"\n",
    "        \n",
    "        if abs(train_split + val_split + test_split - 1.0) > 1e-8:\n",
    "            raise ValueError(f\"Splits must sum to 1.0, got {train_split + val_split + test_split}\")\n",
    "\n",
    "        # Create directories\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            (self.output_dir / 'images' / split).mkdir(parents=True, exist_ok=True)\n",
    "            (self.output_dir / 'labels' / split).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Get all images\n",
    "        all_images = list(self.image_dir.glob('*.jpg')) + list(self.image_dir.glob('*.png'))\n",
    "        \n",
    "        # Separate polyp vs healthy images\n",
    "        polyp_images = [img for img in all_images if img.stem in self.annotations]\n",
    "        healthy_images = [img for img in all_images if img.stem not in self.annotations]\n",
    "        \n",
    "        # **FIX: Shuffle BEFORE splitting to prevent data leakage**\n",
    "        rnd = random.Random(self.seed)\n",
    "        rnd.shuffle(polyp_images)\n",
    "        rnd.shuffle(healthy_images)\n",
    "        \n",
    "        def split_list(lst, train_r, val_r):\n",
    "            n = len(lst)\n",
    "            n_train = int(n * train_r)\n",
    "            n_val = int(n * val_r)\n",
    "            return lst[:n_train], lst[n_train:n_train + n_val], lst[n_train + n_val:]\n",
    "\n",
    "        polyp_train, polyp_val, polyp_test = split_list(polyp_images, train_split, val_split)\n",
    "        healthy_train, healthy_val, healthy_test = split_list(healthy_images, train_split, val_split)\n",
    "\n",
    "        splits = {\n",
    "            'train': polyp_train + healthy_train,\n",
    "            'val': polyp_val + healthy_val,\n",
    "            'test': polyp_test + healthy_test\n",
    "        }\n",
    "\n",
    "        # Shuffle combined splits to mix polyp and healthy images\n",
    "        for split_imgs in splits.values():\n",
    "            rnd.shuffle(split_imgs)\n",
    "\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"DATASET SPLIT\")\n",
    "        print(f\"Train: {len(splits['train'])} ({len(polyp_train)} polyps + {len(healthy_train)} healthy)\")\n",
    "        print(f\"Val:   {len(splits['val'])} ({len(polyp_val)} polyps + {len(healthy_val)} healthy)\")\n",
    "        print(f\"Test:  {len(splits['test'])} ({len(polyp_test)} polyps + {len(healthy_test)} healthy)\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "\n",
    "        # Process each split\n",
    "        for split_name, images in splits.items():\n",
    "            print(f\"Processing {split_name} split ({len(images)} images)...\")\n",
    "            self._process_split(images, split_name)\n",
    "\n",
    "        # Create YAML\n",
    "        self._create_yaml()\n",
    "\n",
    "        print(f\"Segmentation dataset created!\")\n",
    "        print(f\"  Output: {self.output_dir.resolve()}\")\n",
    "\n",
    "\n",
    "    def _process_split(self, image_files, split_name):\n",
    "        img_dir = self.output_dir / 'images' / split_name\n",
    "        label_dir = self.output_dir / 'labels' / split_name\n",
    "\n",
    "        for img_path in image_files:\n",
    "            img_id = img_path.stem\n",
    "\n",
    "            # Load image and copy to output directory\n",
    "            img = cv2.imread(str(img_path))\n",
    "            if img is None:\n",
    "                print(f\"Warning: Could not read {img_path}\")\n",
    "                continue\n",
    "            h, w = img.shape[:2]\n",
    "            shutil.copy(img_path, img_dir / img_path.name)\n",
    "\n",
    "            label_path = label_dir / f\"{img_id}.txt\"\n",
    "\n",
    "            if img_id in self.annotations:\n",
    "                # Polyp image processing\n",
    "                \n",
    "                # Load and prepare mask\n",
    "                mask_path = self.mask_dir / f\"{img_id}.jpg\"\n",
    "                if not mask_path.exists():\n",
    "                    mask_path = self.mask_dir / f\"{img_id}.png\"\n",
    "\n",
    "                if not mask_path.exists():\n",
    "                    print(f\"Warning: Mask not found for {img_id}\")\n",
    "                    continue\n",
    "\n",
    "                mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "                if mask is None:\n",
    "                    print(f\"Warning: Could not read mask for {img_id}\")\n",
    "                    continue\n",
    "\n",
    "                if mask.shape[:2] != (h, w):\n",
    "                    mask = cv2.resize(mask, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "                _, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "                # Get the SINGLE clean polygon (from the mask_to_polygon logic)\n",
    "                polygons = self.mask_to_polygon(mask)\n",
    "                if not polygons:\n",
    "                    print(f\"Warning: No valid polygons for {img_id}. SKIPPING image.\")\n",
    "                    continue\n",
    "\n",
    "                with open(label_path, 'w') as f:\n",
    "                        for polygon in polygons:\n",
    "                            norm_poly = self.normalize_polygon(polygon, w, h)\n",
    "                            # Format for YOLO: class_id x1 y1 x2 y2 ...\n",
    "                            coords = ' '.join(f\"{x:.6f} {y:.6f}\" for x, y in norm_poly)\n",
    "                            f.write(f\"0 {coords}\\n\")\n",
    "            else:\n",
    "                # Healthy image ‚Äî create empty label file\n",
    "                label_path.touch()\n",
    "                \n",
    "    def _create_yaml(self):\n",
    "        \"\"\"Create data.yaml for segmentation.\"\"\"\n",
    "        data = {\n",
    "            'path': str(self.output_dir.resolve()),\n",
    "            'train': 'images/train',\n",
    "            'val': 'images/val',\n",
    "            'test': 'images/test',\n",
    "            'nc': 1,\n",
    "            'names': ['polyp']\n",
    "        }\n",
    "\n",
    "        yaml_path = self.output_dir / 'data.yaml'\n",
    "        # NOTE: Assumes 'yaml' library is available\n",
    "        with open(yaml_path, 'w') as f:\n",
    "            yaml.dump(data, f, default_flow_style=False)\n",
    "        print(f\"\\n  Created: {yaml_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137dab00",
   "metadata": {},
   "source": [
    "PART 2: TRAINING FUNCTION (YOLOv11-seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dbcd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_yolo_seg(data_yaml_path, model_size=MODEL_SIZE, epochs=100, img_size=640, \n",
    "                   batch_size=BATCH_SIZE, workers=4, lr0=1e-4):\n",
    "    \"\"\"Train YOLOv11 Segmentation model.\"\"\"\n",
    "    \n",
    "    # Device detection\n",
    "    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        device = 'mps'\n",
    "        print(\"Using Apple Silicon GPU (MPS)\")\n",
    "    elif torch.cuda.is_available():\n",
    "        device = 0\n",
    "        print(\"Using NVIDIA GPU (CUDA)\")\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "        print(\"Using CPU\")\n",
    "\n",
    "    # Load YOLOv11-seg model\n",
    "    model = YOLO(f'yolo11{model_size}-seg.pt')  # YOLOv11 segmentation\n",
    "\n",
    "    results = model.train(\n",
    "        data=data_yaml_path,\n",
    "        epochs=epochs,\n",
    "        imgsz=img_size,\n",
    "        batch=batch_size,\n",
    "        name='polyp_segmentation_v11',\n",
    "        patience=20,\n",
    "        save=True,\n",
    "        device=device,\n",
    "        workers=workers,\n",
    "        optimizer='AdamW',\n",
    "        project='Kvasir-mask',\n",
    "        \n",
    "        # Learning rate settings\n",
    "        lr0=lr0,\n",
    "        lrf=0.01,\n",
    "        cos_lr=True,\n",
    "        warmup_epochs=5,\n",
    "        warmup_momentum=0.8,\n",
    "        momentum=0.937,\n",
    "        weight_decay=0.001,\n",
    "        dropout=0.1,\n",
    "        \n",
    "        # Multi-scale training\n",
    "        multi_scale=True,\n",
    "        \n",
    "        # Medical imaging augmentations\n",
    "        mosaic=0.0,          # Disabled for medical\n",
    "        mixup=0.0,           # Light mixup\n",
    "        copy_paste=0.0,      # Copy-paste augmentation\n",
    "        erasing=0.1,         # Random erasing\n",
    "        hsv_h=0.01,          # Minimal hue (preserve color)\n",
    "        hsv_s=0.2,\n",
    "        hsv_v=0.2,\n",
    "        degrees=5.0,\n",
    "        translate=0.05,\n",
    "        scale=0.1,\n",
    "        flipud=0.5,\n",
    "        fliplr=0.5,\n",
    "        shear=1.0,\n",
    "        perspective=0.0001,\n",
    "        \n",
    "        # Advanced augmentations\n",
    "        augment=True,\n",
    "        auto_augment='randaugment',\n",
    "        \n",
    "        # Segmentation specific\n",
    "        mask_ratio=4,\n",
    "        overlap_mask=True\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e8c2e7",
   "metadata": {},
   "source": [
    "PART 3: EVALUATION & INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cec91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gt_overlay(img, label_path):\n",
    "    \"\"\"Add ground truth overlay to image (green boxes/masks).\"\"\"\n",
    "    if not label_path.exists():\n",
    "        return img\n",
    "    \n",
    "    h, w = img.shape[:2]\n",
    "    overlay = img.copy()\n",
    "    \n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 5:  # Need at least class + 2 points\n",
    "                continue\n",
    "            \n",
    "            # Parse polygon points\n",
    "            coords = list(map(float, parts[1:]))\n",
    "            points = []\n",
    "            for i in range(0, len(coords), 2):\n",
    "                x = int(coords[i] * w)\n",
    "                y = int(coords[i + 1] * h)\n",
    "                points.append([x, y])\n",
    "            \n",
    "            if len(points) >= 3:\n",
    "                # Draw filled polygon (semi-transparent green)\n",
    "                pts = np.array(points, dtype=np.int32)\n",
    "                cv2.fillPoly(overlay, [pts], (0, 255, 0))\n",
    "                # Draw polygon outline\n",
    "                cv2.polylines(overlay, [pts], True, (0, 200, 0), 2)\n",
    "    \n",
    "    # Blend with original\n",
    "    alpha = 0.3\n",
    "    img = cv2.addWeighted(overlay, alpha, img, 1 - alpha, 0)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def evaluate_model_seg(model_path, data_yaml_path, split_name, conf=0.001, iou=0.5):\n",
    "  \n",
    "    model = YOLO(model_path)\n",
    "    \n",
    "    print(f\"\\nRunning validation with Conf={conf}, IoU={iou} on split: {split_name}\")\n",
    "    metrics = model.val(\n",
    "        data=data_yaml_path, \n",
    "        split=split_name,\n",
    "        conf=conf,\n",
    "        iou=iou\n",
    "    )\n",
    "\n",
    "    # --- CHECK IF SEGMENTATION METRICS EXIST ---\n",
    "    if not hasattr(metrics, 'seg') or metrics.seg is None:\n",
    "        print(\"\\nERROR: This is not a segmentation model! metrics.seg is not available.\")\n",
    "        print(\"Make sure you're using a YOLO-seg model (e.g., yolo-seg.pt)\")\n",
    "        return metrics\n",
    "\n",
    "    # --- GET YOLO'S REPORTED METRICS ---\n",
    "    # These metrics are at the confidence threshold that gives the *optimal F1-score*\n",
    "    # Box metrics\n",
    "    box_p_yolo = metrics.box.p[0] if hasattr(metrics.box, 'p') and len(metrics.box.p) > 0 else 0.0\n",
    "    box_r_yolo = metrics.box.r[0] if hasattr(metrics.box, 'r') and len(metrics.box.r) > 0 else 0.0\n",
    "    box_map50 = metrics.box.map50 if hasattr(metrics.box, 'map50') else 0.0\n",
    "    box_map = metrics.box.map if hasattr(metrics.box, 'map') else 0.0\n",
    "    \n",
    "    # Mask metrics\n",
    "    mask_p_yolo = metrics.seg.p[0] if hasattr(metrics.seg, 'p') and len(metrics.seg.p) > 0 else 0.0\n",
    "    mask_r_yolo = metrics.seg.r[0] if hasattr(metrics.seg, 'r') and len(metrics.seg.r) > 0 else 0.0\n",
    "    mask_map50 = metrics.seg.map50 if hasattr(metrics.seg, 'map50') else 0.0\n",
    "    mask_map = metrics.seg.map if hasattr(metrics.seg, 'map') else 0.0\n",
    "    \n",
    "    # --- Initialize variables for summary ---\n",
    "    total_gt = 0\n",
    "    total_pred = 0\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    precision = 0.0\n",
    "    recall = 0.0\n",
    "    f1 = 0.0\n",
    "\n",
    "    # --- EXTRACT CONFUSION MATRIX ---\n",
    "    # Note: The confusion matrix is calculated at the *specific conf* passed to model.val()\n",
    "    if hasattr(metrics, 'confusion_matrix') and metrics.confusion_matrix is not None:\n",
    "        cm = metrics.confusion_matrix.matrix\n",
    "        \n",
    "        print(f\"\\nDEBUG - Confusion Matrix:\")\n",
    "        print(f\"{cm}\")\n",
    "        print(f\"\\nStructure (for single-class detection):\")\n",
    "        print(f\"  Rows = Predicted, Cols = Actual\")\n",
    "        print(f\"  [[TP, FP],   ‚Üê Row 0: Predicted polyps\")\n",
    "        print(f\"   [FN, TN]]   ‚Üê Row 1: Predicted background\")\n",
    "        print(f\"\\nInterpretation:\")\n",
    "        print(f\"  cm[0,0] = {int(cm[0,0])}: True polyps correctly detected (TP)\")\n",
    "        print(f\"  cm[0,1] = {int(cm[0,1])}: Background predicted as polyp (FP) <--- FALSE POSITIVE\")\n",
    "        print(f\"  cm[1,0] = {int(cm[1,0])}: True polyps missed (FN)            <--- FALSE NEGATIVE\")\n",
    "        print(f\"  cm[1,1] = {int(cm[1,1])}: Background correctly identified (TN)\")\n",
    "        \n",
    "        # Extract TP/FP/FN\n",
    "        TP = int(cm[0, 0])  # Predicted Polyp, Actual Polyp\n",
    "        FP = int(cm[0, 1])  # Predicted Polyp, Actual Background\n",
    "        FN = int(cm[1, 0])  # Predicted Background, Actual Polyp\n",
    "        \n",
    "        total_pred = TP + FP\n",
    "        total_gt = TP + FN\n",
    "        \n",
    "        # Calculate metrics from confusion matrix\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "        \n",
    "        print(f\"\\nCalculated from Confusion Matrix (conf={conf}):\")\n",
    "        print(f\"  Total Ground Truth: {total_gt}\")\n",
    "        print(f\"  Total Predictions:  {total_pred}\")\n",
    "        print(f\"  TP={TP}, FP={FP}, FN={FN}\")\n",
    "        print(f\"  Precision: {precision:.4f} = {TP}/({TP}+{FP})\")\n",
    "        print(f\"  Recall:    {recall:.4f} = {TP}/({TP}+{FN})\")\n",
    "        print(f\"  F1-score:  {f1:.4f}\")\n",
    "        \n",
    "        # Sanity check against metrics.confusion_matrix.nt\n",
    "        # nt[0] = number of targets for class 0 (polyps)\n",
    "        if hasattr(metrics.confusion_matrix, 'nt') and len(metrics.confusion_matrix.nt) > 0:\n",
    "             total_gt_yolo = int(metrics.confusion_matrix.nt[0])\n",
    "             if total_gt_yolo != total_gt:\n",
    "                 print(f\"  WARNING: CM Total GT ({total_gt}) != metrics.nt[0] ({total_gt_yolo})\")\n",
    "             else:\n",
    "                 print(f\"  (Total Ground Truth {total_gt} matches YOLO's instance count)\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\nWARNING: Confusion matrix not available!\")\n",
    "        # Fallback using YOLO's reported metrics (less precise)\n",
    "        precision = box_p_yolo\n",
    "        recall = box_r_yolo\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "        # We can't know TP/FP/FN for sure without the CM at this conf\n",
    "        total_gt = 0 # Unknown\n",
    "        \n",
    "\n",
    "    # --- PRINT SUMMARY ---\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"EVALUATION RESULTS ON {split_name.upper()} SET\")\n",
    "    print(f\"Confidence: {conf} | IoU Threshold: {iou}\")\n",
    "    if total_gt > 0:\n",
    "        print(f\"Total Ground Truth Polyps: {total_gt}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    print(\"\\n### Box (Detection) Metrics\")\n",
    "    print(f\"YOLO Reported (at optimal F1 conf):\")\n",
    "    print(f\"  Precision: {box_p_yolo:.4f}\")\n",
    "    print(f\"  Recall:    {box_r_yolo:.4f}\")\n",
    "    print(f\"  mAP@0.50:  {box_map50:.4f}\")\n",
    "    print(f\"  mAP@0.50:0.95: {box_map:.4f}\")\n",
    "    \n",
    "    if hasattr(metrics, 'confusion_matrix') and metrics.confusion_matrix is not None:\n",
    "        print(f\"\\nFrom Confusion Matrix (at conf={conf}):\")\n",
    "        print(f\"  Total Predicted: {total_pred}\")\n",
    "        print(f\"  TP/FP/FN: {TP}/{FP}/{FN}\")\n",
    "        print(f\"  Precision: {precision:.4f}\")\n",
    "        print(f\"  Recall:    {recall:.4f}\")\n",
    "        print(f\"  F1-score:  {f1:.4f}\")\n",
    "    \n",
    "    print(\"\\n### Mask (Segmentation) Metrics\")\n",
    "    print(f\"YOLO Reported (at optimal F1 conf):\")\n",
    "    print(f\"  Precision: {mask_p_yolo:.4f}\")\n",
    "    print(f\"  Recall:    {mask_r_yolo:.4f}\")\n",
    "    print(f\"  mAP@0.50:  {mask_map50:.4f}\")\n",
    "    print(f\"  mAP@0.50:0.95: {mask_map:.4f}\")\n",
    "    \n",
    "    if hasattr(metrics, 'confusion_matrix') and metrics.confusion_matrix is not None:\n",
    "        print(f\"\\nFrom Confusion Matrix (at conf={conf}):\")\n",
    "        print(f\"  Note: Same TP/FP/FN as box (YOLO uses single confusion matrix)\")\n",
    "        print(f\"  Total Predicted: {total_pred}\")\n",
    "        print(f\"  TP/FP/FN: {TP}/{FP}/{FN}\")\n",
    "        print(f\"  Precision: {precision:.4f}\")\n",
    "        print(f\"  Recall:    {recall:.4f}\")\n",
    "        print(f\"  F1-score:  {f1:.4f}\")\n",
    "    \n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def predict_on_all_images_seg(model_path, image_dir, data_yaml_path=None, \n",
    "                               conf_threshold=0.25, save_dir='predictions_seg', iou=0.5):\n",
    "    \"\"\"\n",
    "    Run inference, save predicted images with GT overlay, and compute statistics.\n",
    "    \"\"\"\n",
    "    model = YOLO(model_path)\n",
    "    image_dir = Path(image_dir)\n",
    "    save_dir = Path(save_dir)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # --- SETUP PATHS ---\n",
    "    # Assumes standard YOLO dataset structure: .../dataset/images/test, .../dataset/labels/test\n",
    "    label_dir = image_dir.parent.parent / 'labels' / image_dir.name\n",
    "    image_files = sorted(list(image_dir.glob(\"*.jpg\")) + list(image_dir.glob(\"*.png\")))\n",
    "\n",
    "    if not image_files:\n",
    "        print(f\"No images found in {image_dir}\")\n",
    "        return\n",
    "\n",
    "    # --- INITIALIZE COUNTERS ---\n",
    "    total_gt_polyps = 0\n",
    "    total_pred_polyps = 0\n",
    "    TP_img = FP_img = FN_img = TN_img = 0\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"1. RUNNING INFERENCE AND VISUALIZATION ON {len(image_files)} IMAGES (Saving GT Overlay)\")\n",
    "    print(f\"   Conf={\n",
    "        \n",
    "        \n",
    "        shold}, IoU={iou}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # --- 1. INFERENCE, VISUALIZATION, AND IMAGE-LEVEL COUNTING LOOP ---\n",
    "    for img_path in image_files:\n",
    "        label_path = label_dir / f\"{img_path.stem}.txt\"\n",
    "        \n",
    "        # Check ground truth\n",
    "        gt_boxes = []\n",
    "        if label_path.exists():\n",
    "            with open(label_path, 'r') as f:\n",
    "                gt_boxes = [line for line in f if line.strip()]\n",
    "        num_gt = len(gt_boxes)\n",
    "        total_gt_polyps += num_gt\n",
    "\n",
    "        # Run inference (single image)\n",
    "        results = model(str(img_path), conf=conf_threshold, iou=iou, verbose=False)\n",
    "        result = results[0] \n",
    "\n",
    "        img_with_results = result.plot()\n",
    "\n",
    "        img_with_gt_overlay = add_gt_overlay(img_with_results, label_path)\n",
    "        \n",
    "        # 3. Save the final image\n",
    "        output_path = save_dir / f\"pred_gt_{img_path.name}\"\n",
    "        img_bgr = img_with_gt_overlay[..., ::-1] \n",
    "        \n",
    "        img_to_save = np.ascontiguousarray(img_bgr, dtype=np.uint8)\n",
    "        cv2.imwrite(str(output_path), img_to_save)\n",
    "        # Count predictions\n",
    "        num_pred = 0\n",
    "        if result.masks is not None:\n",
    "            num_pred = len(result.masks)\n",
    "        \n",
    "        total_pred_polyps += num_pred\n",
    "        \n",
    "        # Contingency matrix (image-level)\n",
    "        if num_gt > 0 and num_pred > 0:\n",
    "            TP_img += 1\n",
    "        elif num_gt == 0 and num_pred > 0:\n",
    "            FP_img += 1\n",
    "        elif num_gt > 0 and num_pred == 0:\n",
    "            FN_img += 1\n",
    "        elif num_gt == 0 and num_pred == 0:\n",
    "            TN_img += 1\n",
    "            \n",
    "        print(f\"  Processed {img_path.name}: GT={num_gt}, Pred={num_pred}\")\n",
    "\n",
    "    # --- 2. CALCULATE IMAGE-LEVEL METRICS ---\n",
    "    \n",
    "    precision_img = TP_img / (TP_img + FP_img) if (TP_img + FP_img) > 0 else 0.0\n",
    "    recall_img = TP_img / (TP_img + FN_img) if (TP_img + FN_img) > 0 else 0.0\n",
    "    f1_score_img = 2 * precision_img * recall_img / (precision_img + recall_img) if (precision_img + recall_img) > 0 else 0.0\n",
    "\n",
    "    # --- 3. FINAL SUMMARY ---\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"FINAL EVALUATION SUMMARY\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    print(f\"Total images:              {len(image_files)}\")\n",
    "    \n",
    "    print(f\"\\n### Image-Level Metrics (Detection/No-Detection)\")\n",
    "    print(f\"  Description: 'Was *any* polyp found in an image that *had* one?'\")\n",
    "    print(f\"  Images with GT & Pred (TP_img): {TP_img}\")\n",
    "    print(f\"  Images with no GT & Pred (FP_img): {FP_img}\")\n",
    "    print(f\"  Images with GT & no Pred (FN_img): {FN_img}\")\n",
    "    print(f\"  Images with no GT & no Pred (TN_img): {TN_img}\")\n",
    "    print(f\"  ---------------------------------\")\n",
    "    print(f\"  Precision (Image-Level): {precision_img:.4f}\")\n",
    "    print(f\"  Recall (Image-Level):    {recall_img:.4f}\")\n",
    "    print(f\"  F1-score (Image-Level):  {f1_score_img:.4f}\")\n",
    "\n",
    "    print(f\"\\n### Polyp-Level Metrics (Object-by-Object)\")\n",
    "    print(f\"  Description: 'Of all {total_gt_polyps} polyps, how many were found?'\")\n",
    "    print(f\"  (Note: This re-runs validation using model.val() for robust metrics)\")\n",
    "    \n",
    "    metrics = None\n",
    "    if data_yaml_path:\n",
    "\n",
    "        metrics = evaluate_model_seg(\n",
    "            model_path=model_path, \n",
    "            data_yaml_path=data_yaml_path, \n",
    "            split_name=image_dir.name, \n",
    "            conf=conf_threshold, \n",
    "            iou=iou\n",
    "        )\n",
    "    else:\n",
    "        print(\"\\nNote: 'data_yaml_path' not provided. Cannot compute robust polyp-level metrics.\")\n",
    "\n",
    "    print(f\"\\nPredictions saved with GT overlay to: {save_dir.resolve()}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Return the metrics of the mask segmentation\n",
    "    if metrics and hasattr(metrics, 'seg'):\n",
    "        mask_p = metrics.seg.p[0] if len(metrics.seg.p) > 0 else 0.0\n",
    "        mask_r = metrics.seg.r[0] if len(metrics.seg.r) > 0 else 0.0\n",
    "        mask_f1 = 2 * mask_p * mask_r / (mask_p + mask_r) if (mask_p + mask_r) > 0 else 0.0\n",
    "        return mask_p, mask_r, mask_f1, metrics.seg.map50, metrics.seg.map\n",
    "    else:\n",
    "        # Fallback if metrics couldn't be calculated\n",
    "        return None, None, None, None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03825d20",
   "metadata": {},
   "source": [
    "Run the model!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b2da8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 1: DATASET PREPARATION (SEGMENTATION)\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "DATASET SPLIT\n",
      "Train: 1050 (700 polyps + 350 healthy)\n",
      "Val:   300 (200 polyps + 100 healthy)\n",
      "Test:  150 (100 polyps + 50 healthy)\n",
      "======================================================================\n",
      "\n",
      "Processing train split (1050 images)...\n",
      "Processing val split (300 images)...\n",
      "Processing test split (150 images)...\n",
      "\n",
      "  Created: Kvasir-mask/kvasir_yolo_seg_dataset/data.yaml\n",
      "Segmentation dataset created!\n",
      "  Output: /home/luca/Desktop/Luca/File-di-kvasir_Daniele/Kvasir-mask/kvasir_yolo_seg_dataset\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "# ========== STEP 1: Dataset Preparation ==========\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 1: DATASET PREPARATION (SEGMENTATION)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "converter = KvasirToYOLOSeg(IMAGE_DIR, MASK_DIR, JSON_PATH, OUTPUT_DIR, seed=SEED)\n",
    "converter.prepare_dataset(train_split=0.7, val_split=0.2, test_split=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8c30da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(f'yolo11{MODEL_SIZE}-seg.pt')  # Replace with your model path if different\n",
    "\n",
    "search_space = {\n",
    "    \"lr0\": (1e-5, 1e-3),\n",
    "    \"lrf\": (0.01, 0.1),\n",
    "    \"momentum\": (0.6, 0.98),\n",
    "    \"weight_decay\": (0.0, 0.001),\n",
    "    \"dfl\": (1.0, 2.0),\n",
    "    \"hsv_h\": (0.0, 0.02),\n",
    "    \"hsv_s\": (0.0, 0.3),\n",
    "    \"hsv_v\": (0.0, 0.3),\n",
    "    \"degrees\": (0.0, 10.0),\n",
    "    \"translate\": (0.0, 0.1),\n",
    "    \"scale\": (0.0, 0.2),\n",
    "    \"shear\": (0.0, 2.0),\n",
    "    \"perspective\": (0.0, 0.0001),\n",
    "    \"flipud\": (0.0, 1.0),\n",
    "    \"fliplr\": (0.0, 1.0),\n",
    "    \"box\": (3.0, 7.5),     # Box loss weight\n",
    "    \"cls\": (0.2, 2.0),\n",
    "    \"seg\": (0.5, 10.0)\n",
    "}\n",
    "\n",
    "model.tune(\n",
    "    data=\"Kvasir-mask/kvasir_yolo_seg_dataset/data.yaml\",\n",
    "    epochs=10,\n",
    "    iterations=100,\n",
    "    optimizer=\"AdamW\",\n",
    "    space=search_space,\n",
    "    plots=True,\n",
    "    save=True,\n",
    "    val=True,\n",
    "    project=\"Kvasir-mask/tune\"  # ‚úÖ Saves results in ./Kvasir_mask/tune/\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d0f94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_hyperparameters():\n",
    "    \"\"\"Search for best_hyperparameters.yaml in tune directory.\"\"\"\n",
    "    tune_dir = Path(\"Kvasir-mask/tune\")\n",
    "    \n",
    "    if not tune_dir.exists():\n",
    "        return None\n",
    "    \n",
    "    # Search recursively for the file\n",
    "    for yaml_file in tune_dir.rglob(\"best_hyperparameters.yaml\"):\n",
    "        print(f\"Found hyperparameters at: {yaml_file}\")\n",
    "        return yaml_file\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def train_yolo_seg_with_tuned_params(data_yaml_path, best_hyperparameters, \n",
    "                                      model_size=MODEL_SIZE, epochs=100, img_size=640, \n",
    "                                      batch_size=BATCH_SIZE, workers=4):\n",
    "    \"\"\"Train with tuned hyperparameters.\"\"\"\n",
    "    \n",
    "    # Device detection\n",
    "    if torch.cuda.is_available():\n",
    "        device = 0\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        device = 'mps'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "\n",
    "    model = YOLO(f'yolo11{model_size}-seg.pt')\n",
    "\n",
    "    # ‚úÖ Merge your fixed settings with tuned parameters\n",
    "    training_args = {\n",
    "        'data': data_yaml_path,\n",
    "        'epochs': epochs,\n",
    "        'imgsz': img_size,\n",
    "        'batch': batch_size,\n",
    "        'name': 'polyp_segmentation_v11_tuned',\n",
    "        'patience': 10,\n",
    "        'save': True,\n",
    "        'device': device,\n",
    "        'workers': workers,\n",
    "        'optimizer': 'AdamW',\n",
    "        'project': 'Kvasir-mask',\n",
    "        \n",
    "        # Fixed settings (always use these)\n",
    "        'multi_scale': True,\n",
    "        'mosaic': 0.0,\n",
    "        'mixup': 0.0,\n",
    "        'copy_paste': 0.0,\n",
    "        'augment': True,\n",
    "        'auto_augment': 'randaugment',\n",
    "        'mask_ratio': 4,\n",
    "        'overlap_mask': True,\n",
    "        \n",
    "        # ‚úÖ Add tuned hyperparameters (these override defaults)\n",
    "        **best_hyperparameters  # This unpacks the dictionary\n",
    "    }\n",
    "\n",
    "    results = model.train(**training_args)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f18fcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== STEP 2: Train YOLOv11-seg ==========\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 2: TRAINING YOLOv11-seg MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "tuned_params_path = find_best_hyperparameters()\n",
    "\n",
    "if tuned_params_path and tuned_params_path.exists():\n",
    "    print(f\"\\n‚úì Found tuned hyperparameters at: {tuned_params_path}\")\n",
    "    \n",
    "    with open(tuned_params_path, 'r') as f:\n",
    "        best_hyperparameters = yaml.safe_load(f)\n",
    "    \n",
    "    print(\"\\nüìã Loaded Hyperparameters:\")\n",
    "    for key, value in best_hyperparameters.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Train with tuned parameters\n",
    "    model = train_yolo_seg_with_tuned_params(\n",
    "        data_yaml_path=DATA_YAML,\n",
    "        best_hyperparameters=best_hyperparameters,\n",
    "        model_size=MODEL_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        img_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    BEST_MODEL_PATH = Path(\"Kvasir-mask/polyp_segmentation_v11_tuned/weights/best.pt\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No tuned parameters found, using defaults...\")\n",
    "    model = train_yolo_seg(\n",
    "        data_yaml_path=DATA_YAML,\n",
    "        model_size=MODEL_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        img_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        lr0=1e-4  # Good starting point for nano\n",
    "    )\n",
    "    BEST_MODEL_PATH = Path(\"Kvasir-mask/polyp_segmentation_v11/weights/best.pt\")\n",
    "\n",
    "print(f\"\\n‚úì Using model: {BEST_MODEL_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69861181",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEST_MODEL_PATH = Path(\"Kvasir-mask/polyp_segmentation_v11_tuned/weights/best.pt\")\n",
    "\n",
    "# ========== Full Test Set Evaluation ==========\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 4B: RUNNING INFERENCE ON ALL TEST IMAGES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "predict_on_all_images_seg(\n",
    "    BEST_MODEL_PATH, \n",
    "    f\"{OUTPUT_DIR}/images/test\",\n",
    "    data_yaml_path=DATA_YAML,\n",
    "    conf_threshold=0.001,\n",
    "    iou=0.5,#increase to be more lax\n",
    "    save_dir='test_predictions_seg'\n",
    ")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*70)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
